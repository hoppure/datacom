{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as tv_models\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import unicodedata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # 테스트셋: 라벨 없이 이미지 경로만 저장\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = '../data/train'\n",
    "test_root = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수: 33137\n",
      "train 이미지 수: 26509, valid 이미지 수: 6628\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 로드\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"총 이미지 수: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform 각각 적용\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseModel Define : resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = tv_models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = BaseModel(num_classes=len(class_names)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base4model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone_name='resnet18', pretrained=True):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if self.backbone_name.startswith('resnet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            self.backbone = timm.create_model(self.backbone_name, pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        # DenseNet 지원 추가!\n",
    "        elif self.backbone_name.startswith('densenet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 backbone: {backbone_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.head(features)\n",
    "        return out\n",
    "    \n",
    "# 여기 모델에서 반복문으로 돌리기.\n",
    "models = [\n",
    "    'densenet121',\n",
    "    'resnet101',         # 추가 추천!\n",
    "    'efficientnet_b3',\n",
    "    'efficientnet_b4',\n",
    "    # 'densenet121',     # 보너스로 추가해도 좋음\n",
    "    # 'vit_base_patch16_224',  # 최신 트렌드 실험용\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /data/ephemeral/home/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 116MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 1/Train]: 100%|██████████| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 1/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 1 | Train Loss: 4.7392 | Val Loss: 3.0668 | Val LogLoss: 3.0658 | Valid Accuracy : 61.9040%\n",
      "✅ Best model saved (LogLoss: 3.0658)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 2/Train]: 100%|██████████| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 2/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 2 | Train Loss: 1.9405 | Val Loss: 1.0119 | Val LogLoss: 1.0110 | Valid Accuracy : 86.0591%\n",
      "✅ Best model saved (LogLoss: 1.0110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 3/Train]: 100%|██████████| 415/415 [06:05<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 3/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 3 | Train Loss: 0.6499 | Val Loss: 0.4832 | Val LogLoss: 0.4827 | Valid Accuracy : 91.2040%\n",
      "✅ Best model saved (LogLoss: 0.4827)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 4/Train]: 100%|██████████| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 4/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 4 | Train Loss: 0.2719 | Val Loss: 0.3241 | Val LogLoss: 0.3240 | Valid Accuracy : 93.0597%\n",
      "✅ Best model saved (LogLoss: 0.3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 5/Train]: 100%|██████████| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 5/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 5 | Train Loss: 0.1396 | Val Loss: 0.2677 | Val LogLoss: 0.2678 | Valid Accuracy : 93.7387%\n",
      "✅ Best model saved (LogLoss: 0.2678)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 6/Train]: 100%|██████████| 415/415 [06:05<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 6/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 6 | Train Loss: 0.0842 | Val Loss: 0.2322 | Val LogLoss: 0.2318 | Valid Accuracy : 94.2667%\n",
      "✅ Best model saved (LogLoss: 0.2318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 7/Train]: 100%|██████████| 415/415 [06:07<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 7/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 7 | Train Loss: 0.0602 | Val Loss: 0.2137 | Val LogLoss: 0.2135 | Valid Accuracy : 94.4176%\n",
      "✅ Best model saved (LogLoss: 0.2135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 8/Train]: 100%|██████████| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 8/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 8 | Train Loss: 0.0478 | Val Loss: 0.2290 | Val LogLoss: 0.2289 | Valid Accuracy : 94.1310%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 9/Train]: 100%|██████████| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 9/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 9 | Train Loss: 0.0384 | Val Loss: 0.2519 | Val LogLoss: 0.2516 | Valid Accuracy : 93.8745%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 10/Train]: 100%|██████████| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 10/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 10 | Train Loss: 0.0347 | Val Loss: 0.2592 | Val LogLoss: 0.2591 | Valid Accuracy : 93.2257%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /data/ephemeral/home/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:01<00:00, 117MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 1/Train]: 100%|██████████| 415/415 [06:44<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 1/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 1 | Train Loss: 3.1271 | Val Loss: 0.8868 | Val LogLoss: 0.8857 | Valid Accuracy : 78.6059%\n",
      "✅ Best model saved (LogLoss: 0.8857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 2/Train]: 100%|██████████| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 2/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 2 | Train Loss: 0.5138 | Val Loss: 0.3627 | Val LogLoss: 0.3615 | Valid Accuracy : 89.5444%\n",
      "✅ Best model saved (LogLoss: 0.3615)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 3/Train]: 100%|██████████| 415/415 [06:42<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 3/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 3 | Train Loss: 0.1906 | Val Loss: 0.2898 | Val LogLoss: 0.2897 | Valid Accuracy : 91.5812%\n",
      "✅ Best model saved (LogLoss: 0.2897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 4/Train]: 100%|██████████| 415/415 [06:42<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 4/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 4 | Train Loss: 0.1222 | Val Loss: 0.2744 | Val LogLoss: 0.2733 | Valid Accuracy : 92.1545%\n",
      "✅ Best model saved (LogLoss: 0.2733)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 5/Train]: 100%|██████████| 415/415 [06:43<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 5/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 5 | Train Loss: 0.0923 | Val Loss: 0.3035 | Val LogLoss: 0.3030 | Valid Accuracy : 91.3398%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 6/Train]: 100%|██████████| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 6/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 6 | Train Loss: 0.0852 | Val Loss: 0.3887 | Val LogLoss: 0.3878 | Valid Accuracy : 89.4991%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 7/Train]: 100%|██████████| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 7/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 7 | Train Loss: 0.0792 | Val Loss: 0.2956 | Val LogLoss: 0.2951 | Valid Accuracy : 91.7773%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 8/Train]: 100%|██████████| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 8/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 8 | Train Loss: 0.0525 | Val Loss: 0.2612 | Val LogLoss: 0.2607 | Valid Accuracy : 93.1352%\n",
      "✅ Best model saved (LogLoss: 0.2607)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 9/Train]: 100%|██████████| 415/415 [06:45<00:00,  1.02it/s]\n",
      "[resnet101 Epoch 9/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 9 | Train Loss: 0.0637 | Val Loss: 0.4339 | Val LogLoss: 0.4340 | Valid Accuracy : 89.0616%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 10/Train]: 100%|██████████| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 10/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 10 | Train Loss: 0.0672 | Val Loss: 0.3311 | Val LogLoss: 0.3309 | Valid Accuracy : 92.0187%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45724be8d9cb44b4a19f5425230aefb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: efficientnet_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 1/Train]: 100%|██████████| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 1/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 1 | Train Loss: 4.6966 | Val Loss: 2.3128 | Val LogLoss: 2.3110 | Valid Accuracy : 59.7918%\n",
      "✅ Best model saved (LogLoss: 2.3110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 2/Train]: 100%|██████████| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 2/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 2 | Train Loss: 1.1863 | Val Loss: 0.5865 | Val LogLoss: 0.5856 | Valid Accuracy : 86.9493%\n",
      "✅ Best model saved (LogLoss: 0.5856)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 3/Train]: 100%|██████████| 415/415 [06:02<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 3/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 3 | Train Loss: 0.3415 | Val Loss: 0.3439 | Val LogLoss: 0.3434 | Valid Accuracy : 90.8570%\n",
      "✅ Best model saved (LogLoss: 0.3434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 4/Train]: 100%|██████████| 415/415 [06:02<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 4/Val]: 100%|██████████| 104/104 [01:24<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 4 | Train Loss: 0.1466 | Val Loss: 0.2744 | Val LogLoss: 0.2736 | Valid Accuracy : 92.1394%\n",
      "✅ Best model saved (LogLoss: 0.2736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 5/Train]: 100%|██████████| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 5/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 5 | Train Loss: 0.0774 | Val Loss: 0.2686 | Val LogLoss: 0.2683 | Valid Accuracy : 92.6222%\n",
      "✅ Best model saved (LogLoss: 0.2683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 6/Train]: 100%|██████████| 415/415 [06:00<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 6/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 6 | Train Loss: 0.0472 | Val Loss: 0.2517 | Val LogLoss: 0.2510 | Valid Accuracy : 92.9390%\n",
      "✅ Best model saved (LogLoss: 0.2510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 7/Train]: 100%|██████████| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 7/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 7 | Train Loss: 0.0289 | Val Loss: 0.2547 | Val LogLoss: 0.2541 | Valid Accuracy : 93.2710%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 8/Train]: 100%|██████████| 415/415 [06:02<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 8/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 8 | Train Loss: 0.0197 | Val Loss: 0.2612 | Val LogLoss: 0.2612 | Valid Accuracy : 93.1955%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 9/Train]: 100%|██████████| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 9/Val]: 100%|██████████| 104/104 [01:24<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 9 | Train Loss: 0.0182 | Val Loss: 0.2545 | Val LogLoss: 0.2545 | Valid Accuracy : 93.3917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 10/Train]: 100%|██████████| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 10/Val]: 100%|██████████| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 10 | Train Loss: 0.0129 | Val Loss: 0.2490 | Val LogLoss: 0.2493 | Valid Accuracy : 93.6029%\n",
      "✅ Best model saved (LogLoss: 0.2493)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24203036fc14603bb36f118f5e86dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 1/Train]: 100%|██████████| 415/415 [06:44<00:00,  1.03it/s]\n",
      "[efficientnet_b4 Epoch 1/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 1 | Train Loss: 4.8495 | Val Loss: 2.2196 | Val LogLoss: 2.2183 | Valid Accuracy : 51.6295%\n",
      "✅ Best model saved (LogLoss: 2.2183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 2/Train]: 100%|██████████| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 2/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 2 | Train Loss: 1.1877 | Val Loss: 0.8588 | Val LogLoss: 0.8576 | Valid Accuracy : 78.4852%\n",
      "✅ Best model saved (LogLoss: 0.8576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 3/Train]: 100%|██████████| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 3/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 3 | Train Loss: 0.4258 | Val Loss: 0.5831 | Val LogLoss: 0.5828 | Valid Accuracy : 84.8974%\n",
      "✅ Best model saved (LogLoss: 0.5828)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 4/Train]: 100%|██████████| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 4/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 4 | Train Loss: 0.2000 | Val Loss: 0.4780 | Val LogLoss: 0.4781 | Valid Accuracy : 87.2209%\n",
      "✅ Best model saved (LogLoss: 0.4781)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 5/Train]: 100%|██████████| 415/415 [06:37<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 5/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 5 | Train Loss: 0.1031 | Val Loss: 0.4382 | Val LogLoss: 0.4376 | Valid Accuracy : 88.4581%\n",
      "✅ Best model saved (LogLoss: 0.4376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 6/Train]: 100%|██████████| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 6/Val]: 100%|██████████| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 6 | Train Loss: 0.0555 | Val Loss: 0.4083 | Val LogLoss: 0.4082 | Valid Accuracy : 89.0616%\n",
      "✅ Best model saved (LogLoss: 0.4082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 7/Train]: 100%|██████████| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 7/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 7 | Train Loss: 0.0324 | Val Loss: 0.3923 | Val LogLoss: 0.3920 | Valid Accuracy : 89.4991%\n",
      "✅ Best model saved (LogLoss: 0.3920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 8/Train]: 100%|██████████| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 8/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 8 | Train Loss: 0.0206 | Val Loss: 0.3898 | Val LogLoss: 0.3896 | Valid Accuracy : 89.8612%\n",
      "✅ Best model saved (LogLoss: 0.3896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 9/Train]: 100%|██████████| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 9/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 9 | Train Loss: 0.0130 | Val Loss: 0.3864 | Val LogLoss: 0.3864 | Valid Accuracy : 89.7858%\n",
      "✅ Best model saved (LogLoss: 0.3864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 10/Train]: 100%|██████████| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 10/Val]: 100%|██████████| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 10 | Train Loss: 0.0098 | Val Loss: 0.3802 | Val LogLoss: 0.3802 | Valid Accuracy : 90.1177%\n",
      "✅ Best model saved (LogLoss: 0.3802)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for backbone_name in models:\n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name = backbone_name).to(device)\n",
    "\n",
    "    print(f\"\\n🚀 Training Model: {backbone_name} \\n\\n\")\n",
    "    # 기준값 초기화\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    # 손실 함수\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 옵티마이저\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "    # 스케줄러\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    # 학습 및 검증 루프 \n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # LogLoss\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "                f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "                f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "        \n",
    "        scheduler.step(val_logloss)\n",
    "\n",
    "        # Best model 저장\n",
    "        \n",
    "        if val_logloss < best_logloss:\n",
    "            best_logloss = val_logloss\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "            print(f\"✅ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"🛑 Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    del model  # 모델 학습 후 메모리 해제\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 작성중\n",
    "\n",
    "# 모델 불러오기\n",
    "model = BaseModel(num_classes=len(class_names), backbone_name='efficientnet_b4').to(device)\n",
    "model.load_state_dict(torch.load('best_efficientnet_b4_epoch10.pth'))\n",
    "backbone_name = 'efficientnet_b4'\n",
    "# 옵티마이저/스케줄러 재설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "# 이어서 학습\n",
    "for epoch in range(10, 20):  # 11~20에포크\n",
    "    print(f\"\\n🚀 Training Model: {backbone_name} \\n\\n\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # 추가 학습 전 검증 수행으로 best_logloss 초기화\n",
    "    model.eval()\n",
    "    val_loss, val_logloss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    best_logloss = val_logloss\n",
    "    no_improve = 0\n",
    "    patience = 5  # patience도 정의 필요\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "            f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "    \n",
    "    scheduler.step(val_logloss)\n",
    "\n",
    "    # Best model 저장\n",
    "    \n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "        print(f\"✅ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"🛑 Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "del model  # 모델 학습 후 메모리 해제\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "records = ['best_densenet121_epoch7.pth','best_efficientnet_b3_epoch10.pth',\n",
    "           'best_efficientnet_b4_epoch10.pth','best_resnet101_epoch8.pth']\n",
    "\n",
    "for record in records:\n",
    "    # 저장된 모델 로드\n",
    "    parts = record.split('_')\n",
    "# 올바른 조건문\n",
    "    if record in ['best_densenet121_epoch7.pth', 'best_resnet101_epoch8.pth']:\n",
    "        backbone_name = f\"{parts[1]}\"  # densenet121 등\n",
    "    else:\n",
    "        backbone_name = f\"{parts[1]}_{parts[2]}\"  # efficientnet_b3 등\n",
    "    \n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name=backbone_name)\n",
    "    model.load_state_dict(torch.load(record, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # 추론\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # 각 배치의 확률을 리스트로 변환\n",
    "            for prob in probs.cpu():  # prob: (num_classes,)\n",
    "                result = {\n",
    "                    class_names[i]: prob[i].item()\n",
    "                    for i in range(len(class_names))\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    pred = pd.DataFrame(results)\n",
    "\n",
    "    submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
    "    \n",
    "    class_columns = submission.columns[1:]\n",
    "    pred.columns = normalize_cols(pred.columns)\n",
    "    class_columns = normalize_cols(class_columns)\n",
    "    pred = pred[class_columns]\n",
    "\n",
    "    submission[class_columns] = pred.values\n",
    "    submission.to_csv(f'{record}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1시리즈_F20_2013_2015</th>\n",
       "      <th>1시리즈_F20_2016_2019</th>\n",
       "      <th>1시리즈_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2시리즈_그란쿠페_F44_2020_2024</th>\n",
       "      <th>2시리즈_액티브_투어러_F45_2019_2021</th>\n",
       "      <th>2시리즈_액티브_투어러_U06_2022_2024</th>\n",
       "      <th>3008_2세대_2018_2023</th>\n",
       "      <th>3시리즈_E90_2005_2012</th>\n",
       "      <th>3시리즈_F30_2013_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>티볼리_에어_2021_2022</th>\n",
       "      <th>파나메라_2010_2016</th>\n",
       "      <th>파나메라_971_2017_2023</th>\n",
       "      <th>파사트_GT_B8_2018_2022</th>\n",
       "      <th>파일럿_3세대_2016_2018</th>\n",
       "      <th>팰리세이드_2019_2022</th>\n",
       "      <th>팰리세이드_LX3_2025</th>\n",
       "      <th>프리우스_4세대_2016_2018</th>\n",
       "      <th>프리우스_4세대_2019_2022</th>\n",
       "      <th>프리우스_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.511935e-07</td>\n",
       "      <td>1.445385e-06</td>\n",
       "      <td>1.592065e-07</td>\n",
       "      <td>4.357784e-06</td>\n",
       "      <td>3.298061e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.070755e-07</td>\n",
       "      <td>7.793965e-07</td>\n",
       "      <td>2.955839e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.812796e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.839943e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.176699e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.151721e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.752513e-05</td>\n",
       "      <td>9.487465e-05</td>\n",
       "      <td>1.280151e-04</td>\n",
       "      <td>3.506709e-05</td>\n",
       "      <td>3.918644e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.326350e-04</td>\n",
       "      <td>7.821716e-05</td>\n",
       "      <td>1.066425e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.235167e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.742213e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.497383e-05</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5.077703e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.293226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629503e-05</td>\n",
       "      <td>1.849107e-05</td>\n",
       "      <td>1.507656e-04</td>\n",
       "      <td>6.678894e-06</td>\n",
       "      <td>6.522421e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.378862e-04</td>\n",
       "      <td>1.058777e-05</td>\n",
       "      <td>5.987513e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142872e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.057245e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.381332e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.378176e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.411537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.519213e-06</td>\n",
       "      <td>1.676211e-07</td>\n",
       "      <td>1.582139e-06</td>\n",
       "      <td>5.283350e-07</td>\n",
       "      <td>2.171661e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.027208e-05</td>\n",
       "      <td>3.179571e-06</td>\n",
       "      <td>2.785918e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961595e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.668167e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.549510e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.212071e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.782074e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.922888e-04</td>\n",
       "      <td>5.125251e-03</td>\n",
       "      <td>4.367732e-05</td>\n",
       "      <td>5.357838e-06</td>\n",
       "      <td>1.428535e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.358307e-06</td>\n",
       "      <td>1.325173e-06</td>\n",
       "      <td>5.119073e-05</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.372026e-06</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.196302e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.170576e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.873700e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.729611e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1시리즈_F20_2013_2015  1시리즈_F20_2016_2019  1시리즈_F40_2020_2024  \\\n",
       "0           7.511935e-07           1.445385e-06           1.592065e-07   \n",
       "1           5.752513e-05           9.487465e-05           1.280151e-04   \n",
       "2           5.629503e-05           1.849107e-05           1.507656e-04   \n",
       "3           3.519213e-06           1.676211e-07           1.582139e-06   \n",
       "4           1.922888e-04           5.125251e-03           4.367732e-05   \n",
       "\n",
       "   2008_2015_2017  2시리즈_그란쿠페_F44_2020_2024  \\\n",
       "0    4.357784e-06                     3.298061e-07   \n",
       "1    3.506709e-05                     3.918644e-05   \n",
       "2    6.678894e-06                     6.522421e-05   \n",
       "3    5.283350e-07                     2.171661e-06   \n",
       "4    5.357838e-06                     1.428535e-05   \n",
       "\n",
       "   2시리즈_액티브_투어러_F45_2019_2021  2시리즈_액티브_투어러_U06_2022_2024  \\\n",
       "0                              0.000002                          7.070755e-07   \n",
       "1                              0.000038                          6.326350e-04   \n",
       "2                              0.000003                          2.378862e-04   \n",
       "3                              0.000002                          2.027208e-05   \n",
       "4                              0.000098                          1.358307e-06   \n",
       "\n",
       "   3008_2세대_2018_2023  3시리즈_E90_2005_2012  3시리즈_F30_2013_2018  ...  \\\n",
       "0          7.793965e-07           2.955839e-07               0.000001  ...   \n",
       "1          7.821716e-05           1.066425e-04               0.000031  ...   \n",
       "2          1.058777e-05           5.987513e-07               0.000010  ...   \n",
       "3          3.179571e-06           2.785918e-06               0.000004  ...   \n",
       "4          1.325173e-06           5.119073e-05               0.000526  ...   \n",
       "\n",
       "   티볼리_에어_2021_2022  파나메라_2010_2016  파나메라_971_2017_2023  \\\n",
       "0            5.704890e-07            0.000002            8.812796e-07   \n",
       "1            7.235167e-05            0.000015            1.742213e-05   \n",
       "2            1.142872e-05            0.000008            1.057245e-04   \n",
       "3            3.961595e-07            0.000004            3.668167e-05   \n",
       "4            1.372026e-06            0.000060            1.196302e-06   \n",
       "\n",
       "   파사트_GT_B8_2018_2022  파일럿_3세대_2016_2018  팰리세이드_2019_2022  \\\n",
       "0                0.000001              2.839943e-06               0.000003   \n",
       "1                0.000015              2.497383e-05               0.000106   \n",
       "2                0.000014              2.381332e-05               0.000005   \n",
       "3                0.000008              8.549510e-07               0.000019   \n",
       "4                0.000009              3.170576e-07               0.000004   \n",
       "\n",
       "   팰리세이드_LX3_2025  프리우스_4세대_2016_2018  프리우스_4세대_2019_2022  \\\n",
       "0          1.176699e-05                  0.000002                  0.000012   \n",
       "1          5.077703e-05                  0.000010                  0.000041   \n",
       "2          1.378176e-05                  0.000003                  0.000029   \n",
       "3          1.212071e-05                  0.000002                  0.000006   \n",
       "4          4.873700e-07                  0.000006                  0.000002   \n",
       "\n",
       "   프리우스_C_2018_2020  \n",
       "0          1.151721e-06  \n",
       "1          1.293226e-05  \n",
       "2          2.411537e-06  \n",
       "3          5.782074e-07  \n",
       "4          6.729611e-06  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1시리즈_F20_2013_2015</th>\n",
       "      <th>1시리즈_F20_2016_2019</th>\n",
       "      <th>1시리즈_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2시리즈_그란쿠페_F44_2020_2024</th>\n",
       "      <th>2시리즈_액티브_투어러_F45_2019_2021</th>\n",
       "      <th>2시리즈_액티브_투어러_U06_2022_2024</th>\n",
       "      <th>3008_2세대_2018_2023</th>\n",
       "      <th>3시리즈_E90_2005_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>티볼리_에어_2021_2022</th>\n",
       "      <th>파나메라_2010_2016</th>\n",
       "      <th>파나메라_971_2017_2023</th>\n",
       "      <th>파사트_GT_B8_2018_2022</th>\n",
       "      <th>파일럿_3세대_2016_2018</th>\n",
       "      <th>팰리세이드_2019_2022</th>\n",
       "      <th>팰리세이드_LX3_2025</th>\n",
       "      <th>프리우스_4세대_2016_2018</th>\n",
       "      <th>프리우스_4세대_2019_2022</th>\n",
       "      <th>프리우스_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  1시리즈_F20_2013_2015  1시리즈_F20_2016_2019  1시리즈_F40_2020_2024  \\\n",
       "0  TEST_00000                   1                 0.0                 0.0   \n",
       "1  TEST_00001                   1                 0.0                 0.0   \n",
       "2  TEST_00002                   1                 0.0                 0.0   \n",
       "3  TEST_00003                   1                 0.0                 0.0   \n",
       "4  TEST_00004                   1                 0.0                 0.0   \n",
       "\n",
       "   2008_2015_2017  2시리즈_그란쿠페_F44_2020_2024  2시리즈_액티브_투어러_F45_2019_2021  \\\n",
       "0             0.0                      0.0                         0.0   \n",
       "1             0.0                      0.0                         0.0   \n",
       "2             0.0                      0.0                         0.0   \n",
       "3             0.0                      0.0                         0.0   \n",
       "4             0.0                      0.0                         0.0   \n",
       "\n",
       "   2시리즈_액티브_투어러_U06_2022_2024  3008_2세대_2018_2023  3시리즈_E90_2005_2012  ...  \\\n",
       "0                         0.0                 0.0                 0.0  ...   \n",
       "1                         0.0                 0.0                 0.0  ...   \n",
       "2                         0.0                 0.0                 0.0  ...   \n",
       "3                         0.0                 0.0                 0.0  ...   \n",
       "4                         0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   티볼리_에어_2021_2022  파나메라_2010_2016  파나메라_971_2017_2023  파사트_GT_B8_2018_2022  \\\n",
       "0               0.0             0.0                 0.0                  0.0   \n",
       "1               0.0             0.0                 0.0                  0.0   \n",
       "2               0.0             0.0                 0.0                  0.0   \n",
       "3               0.0             0.0                 0.0                  0.0   \n",
       "4               0.0             0.0                 0.0                  0.0   \n",
       "\n",
       "   파일럿_3세대_2016_2018  팰리세이드_2019_2022  팰리세이드_LX3_2025  프리우스_4세대_2016_2018  \\\n",
       "0                0.0              0.0             0.0                 0.0   \n",
       "1                0.0              0.0             0.0                 0.0   \n",
       "2                0.0              0.0             0.0                 0.0   \n",
       "3                0.0              0.0             0.0                 0.0   \n",
       "4                0.0              0.0             0.0                 0.0   \n",
       "\n",
       "   프리우스_4세대_2019_2022  프리우스_C_2018_2020  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019', '1시리즈_F40_2020_2024',\n",
      "       '2008_2015_2017', '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021', '2시리즈_액티브_투어러_U06_2022_2024',\n",
      "       '3008_2세대_2018_2023', '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016', '파나메라_971_2017_2023',\n",
      "       '파사트_GT_B8_2018_2022', '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018', '프리우스_4세대_2019_2022',\n",
      "       '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "class_columns = submission.columns[1:]\n",
    "\n",
    "print(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019',\n",
      "       '1시리즈_F40_2020_2024', '2008_2015_2017',\n",
      "       '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021',\n",
      "       '2시리즈_액티브_투어러_U06_2022_2024', '3008_2세대_2018_2023',\n",
      "       '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016',\n",
      "       '파나메라_971_2017_2023', '파사트_GT_B8_2018_2022',\n",
      "       '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018',\n",
      "       '프리우스_4세대_2019_2022', '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n",
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019', '1시리즈_F40_2020_2024',\n",
      "       '2008_2015_2017', '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021', '2시리즈_액티브_투어러_U06_2022_2024',\n",
      "       '3008_2세대_2018_2023', '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016', '파나메라_971_2017_2023',\n",
      "       '파사트_GT_B8_2018_2022', '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018', '프리우스_4세대_2019_2022',\n",
      "       '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "print(pred.columns)\n",
    "print(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼명이 완전히 일치합니다!\n"
     ]
    }
   ],
   "source": [
    "if list(pred.columns) == list(class_columns):\n",
    "    print(\"컬럼명이 완전히 일치합니다!\")\n",
    "else:\n",
    "    print(\"컬럼명이 다릅니다!\")\n",
    "    print(\"pred에만 있는 컬럼:\", set(pred.columns) - set(class_columns))\n",
    "    print(\"class_columns에만 있는 컬럼:\", set(class_columns) - set(pred.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEtric = LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "\n",
    "def multiclass_log_loss(answer_df, submission_df):\n",
    "    class_list = sorted(answer_df['label'].unique())\n",
    "    \n",
    "    if submission_df.shape[0] != answer_df.shape[0]:\n",
    "        raise ValueError(\"submission_df 행 개수가 answer_df와 일치하지 않습니다.\")\n",
    "\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    if not all(answer_df['ID'] == submission_df['ID']):\n",
    "        raise ValueError(\"ID가 정렬되지 않았거나 불일치합니다.\")\n",
    "    \n",
    "    missing_cols = [col for col in class_list if col not in submission_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"클래스 컬럼 누락: {missing_cols}\")\n",
    "    \n",
    "    if submission_df[class_list].isnull().any().any():\n",
    "        raise ValueError(\"NaN 포함됨\")\n",
    "    for col in class_list:\n",
    "        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():\n",
    "            raise ValueError(f\"{col}의 확률값이 0~1 범위 초과\")\n",
    "\n",
    "    # 정답 인덱스 변환\n",
    "    true_labels = answer_df['label'].tolist()\n",
    "    true_idx = [class_list.index(lbl) for lbl in true_labels]\n",
    "\n",
    "    # 확률 정규화 + clip\n",
    "    probs = submission_df[class_list].values\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))\n",
    "\n",
    "# 예시 데이터 (클래스 3개: A, B, C)\n",
    "answer_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'label': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'A': [0.7, 0.1, 0.2],\n",
    "    'B': [0.2, 0.8, 0.3],\n",
    "    'C': [0.1, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# 함수 실행\n",
    "loss = multiclass_log_loss(answer_df, submission_df)\n",
    "print(f\"Log Loss: {loss:.6f}\") # Log Loss: 0.424322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
