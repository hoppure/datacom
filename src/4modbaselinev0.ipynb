{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as tv_models\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import unicodedata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = '../data/train'\n",
    "test_root = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 33137\n",
      "train ì´ë¯¸ì§€ ìˆ˜: 26509, valid ì´ë¯¸ì§€ ìˆ˜: 6628\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform ê°ê° ì ìš©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseModel Define : resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = tv_models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = BaseModel(num_classes=len(class_names)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base4model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone_name='resnet18', pretrained=True):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if self.backbone_name.startswith('resnet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            self.backbone = timm.create_model(self.backbone_name, pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        # DenseNet ì§€ì› ì¶”ê°€!\n",
    "        elif self.backbone_name.startswith('densenet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” backbone: {backbone_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.head(features)\n",
    "        return out\n",
    "    \n",
    "# ì—¬ê¸° ëª¨ë¸ì—ì„œ ë°˜ë³µë¬¸ìœ¼ë¡œ ëŒë¦¬ê¸°.\n",
    "models = [\n",
    "    'densenet121',\n",
    "    'resnet101',         # ì¶”ê°€ ì¶”ì²œ!\n",
    "    'efficientnet_b3',\n",
    "    'efficientnet_b4',\n",
    "    # 'densenet121',     # ë³´ë„ˆìŠ¤ë¡œ ì¶”ê°€í•´ë„ ì¢‹ìŒ\n",
    "    # 'vit_base_patch16_224',  # ìµœì‹  íŠ¸ë Œë“œ ì‹¤í—˜ìš©\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /data/ephemeral/home/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 116MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 1/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 1/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 1 | Train Loss: 4.7392 | Val Loss: 3.0668 | Val LogLoss: 3.0658 | Valid Accuracy : 61.9040%\n",
      "âœ… Best model saved (LogLoss: 3.0658)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 2/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 2/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 2 | Train Loss: 1.9405 | Val Loss: 1.0119 | Val LogLoss: 1.0110 | Valid Accuracy : 86.0591%\n",
      "âœ… Best model saved (LogLoss: 1.0110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 3/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:05<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 3/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 3 | Train Loss: 0.6499 | Val Loss: 0.4832 | Val LogLoss: 0.4827 | Valid Accuracy : 91.2040%\n",
      "âœ… Best model saved (LogLoss: 0.4827)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 4/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 4/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 4 | Train Loss: 0.2719 | Val Loss: 0.3241 | Val LogLoss: 0.3240 | Valid Accuracy : 93.0597%\n",
      "âœ… Best model saved (LogLoss: 0.3240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 5/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 5/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 5 | Train Loss: 0.1396 | Val Loss: 0.2677 | Val LogLoss: 0.2678 | Valid Accuracy : 93.7387%\n",
      "âœ… Best model saved (LogLoss: 0.2678)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 6/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:05<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 6/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 6 | Train Loss: 0.0842 | Val Loss: 0.2322 | Val LogLoss: 0.2318 | Valid Accuracy : 94.2667%\n",
      "âœ… Best model saved (LogLoss: 0.2318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 7/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:07<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 7/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 7 | Train Loss: 0.0602 | Val Loss: 0.2137 | Val LogLoss: 0.2135 | Valid Accuracy : 94.4176%\n",
      "âœ… Best model saved (LogLoss: 0.2135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 8/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 8/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 8 | Train Loss: 0.0478 | Val Loss: 0.2290 | Val LogLoss: 0.2289 | Valid Accuracy : 94.1310%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 9/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:06<00:00,  1.13it/s]\n",
      "[densenet121 Epoch 9/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 9 | Train Loss: 0.0384 | Val Loss: 0.2519 | Val LogLoss: 0.2516 | Valid Accuracy : 93.8745%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 10/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[densenet121 Epoch 10/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[densenet121] Epoch 10 | Train Loss: 0.0347 | Val Loss: 0.2592 | Val LogLoss: 0.2591 | Valid Accuracy : 93.2257%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /data/ephemeral/home/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171M/171M [00:01<00:00, 117MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 1/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:44<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 1/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 1 | Train Loss: 3.1271 | Val Loss: 0.8868 | Val LogLoss: 0.8857 | Valid Accuracy : 78.6059%\n",
      "âœ… Best model saved (LogLoss: 0.8857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 2/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 2/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 2 | Train Loss: 0.5138 | Val Loss: 0.3627 | Val LogLoss: 0.3615 | Valid Accuracy : 89.5444%\n",
      "âœ… Best model saved (LogLoss: 0.3615)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 3/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:42<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 3/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 3 | Train Loss: 0.1906 | Val Loss: 0.2898 | Val LogLoss: 0.2897 | Valid Accuracy : 91.5812%\n",
      "âœ… Best model saved (LogLoss: 0.2897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 4/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:42<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 4/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 4 | Train Loss: 0.1222 | Val Loss: 0.2744 | Val LogLoss: 0.2733 | Valid Accuracy : 92.1545%\n",
      "âœ… Best model saved (LogLoss: 0.2733)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 5/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:43<00:00,  1.03it/s]\n",
      "[resnet101 Epoch 5/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 5 | Train Loss: 0.0923 | Val Loss: 0.3035 | Val LogLoss: 0.3030 | Valid Accuracy : 91.3398%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 6/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 6/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 6 | Train Loss: 0.0852 | Val Loss: 0.3887 | Val LogLoss: 0.3878 | Valid Accuracy : 89.4991%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 7/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 7/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 7 | Train Loss: 0.0792 | Val Loss: 0.2956 | Val LogLoss: 0.2951 | Valid Accuracy : 91.7773%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 8/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 8/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 8 | Train Loss: 0.0525 | Val Loss: 0.2612 | Val LogLoss: 0.2607 | Valid Accuracy : 93.1352%\n",
      "âœ… Best model saved (LogLoss: 0.2607)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 9/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:45<00:00,  1.02it/s]\n",
      "[resnet101 Epoch 9/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 9 | Train Loss: 0.0637 | Val Loss: 0.4339 | Val LogLoss: 0.4340 | Valid Accuracy : 89.0616%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 10/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:40<00:00,  1.04it/s]\n",
      "[resnet101 Epoch 10/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet101] Epoch 10 | Train Loss: 0.0672 | Val Loss: 0.3311 | Val LogLoss: 0.3309 | Valid Accuracy : 92.0187%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45724be8d9cb44b4a19f5425230aefb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: efficientnet_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 1/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 1/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 1 | Train Loss: 4.6966 | Val Loss: 2.3128 | Val LogLoss: 2.3110 | Valid Accuracy : 59.7918%\n",
      "âœ… Best model saved (LogLoss: 2.3110)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 2/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 2/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 2 | Train Loss: 1.1863 | Val Loss: 0.5865 | Val LogLoss: 0.5856 | Valid Accuracy : 86.9493%\n",
      "âœ… Best model saved (LogLoss: 0.5856)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 3/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:02<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 3/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 3 | Train Loss: 0.3415 | Val Loss: 0.3439 | Val LogLoss: 0.3434 | Valid Accuracy : 90.8570%\n",
      "âœ… Best model saved (LogLoss: 0.3434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 4/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:02<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 4/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:24<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 4 | Train Loss: 0.1466 | Val Loss: 0.2744 | Val LogLoss: 0.2736 | Valid Accuracy : 92.1394%\n",
      "âœ… Best model saved (LogLoss: 0.2736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 5/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 5/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 5 | Train Loss: 0.0774 | Val Loss: 0.2686 | Val LogLoss: 0.2683 | Valid Accuracy : 92.6222%\n",
      "âœ… Best model saved (LogLoss: 0.2683)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 6/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:00<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 6/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 6 | Train Loss: 0.0472 | Val Loss: 0.2517 | Val LogLoss: 0.2510 | Valid Accuracy : 92.9390%\n",
      "âœ… Best model saved (LogLoss: 0.2510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 7/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 7/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 7 | Train Loss: 0.0289 | Val Loss: 0.2547 | Val LogLoss: 0.2541 | Valid Accuracy : 93.2710%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 8/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:02<00:00,  1.15it/s]\n",
      "[efficientnet_b3 Epoch 8/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 8 | Train Loss: 0.0197 | Val Loss: 0.2612 | Val LogLoss: 0.2612 | Valid Accuracy : 93.1955%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 9/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:04<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 9/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:24<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 9 | Train Loss: 0.0182 | Val Loss: 0.2545 | Val LogLoss: 0.2545 | Valid Accuracy : 93.3917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3 Epoch 10/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:03<00:00,  1.14it/s]\n",
      "[efficientnet_b3 Epoch 10/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:25<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b3] Epoch 10 | Train Loss: 0.0129 | Val Loss: 0.2490 | Val LogLoss: 0.2493 | Valid Accuracy : 93.6029%\n",
      "âœ… Best model saved (LogLoss: 0.2493)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24203036fc14603bb36f118f5e86dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 1/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:44<00:00,  1.03it/s]\n",
      "[efficientnet_b4 Epoch 1/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 1 | Train Loss: 4.8495 | Val Loss: 2.2196 | Val LogLoss: 2.2183 | Valid Accuracy : 51.6295%\n",
      "âœ… Best model saved (LogLoss: 2.2183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 2/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 2/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 2 | Train Loss: 1.1877 | Val Loss: 0.8588 | Val LogLoss: 0.8576 | Valid Accuracy : 78.4852%\n",
      "âœ… Best model saved (LogLoss: 0.8576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 3/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:38<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 3/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 3 | Train Loss: 0.4258 | Val Loss: 0.5831 | Val LogLoss: 0.5828 | Valid Accuracy : 84.8974%\n",
      "âœ… Best model saved (LogLoss: 0.5828)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 4/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 4/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 4 | Train Loss: 0.2000 | Val Loss: 0.4780 | Val LogLoss: 0.4781 | Valid Accuracy : 87.2209%\n",
      "âœ… Best model saved (LogLoss: 0.4781)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 5/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:37<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 5/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 5 | Train Loss: 0.1031 | Val Loss: 0.4382 | Val LogLoss: 0.4376 | Valid Accuracy : 88.4581%\n",
      "âœ… Best model saved (LogLoss: 0.4376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 6/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 6/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:27<00:00,  1.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 6 | Train Loss: 0.0555 | Val Loss: 0.4083 | Val LogLoss: 0.4082 | Valid Accuracy : 89.0616%\n",
      "âœ… Best model saved (LogLoss: 0.4082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 7/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:39<00:00,  1.04it/s]\n",
      "[efficientnet_b4 Epoch 7/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 7 | Train Loss: 0.0324 | Val Loss: 0.3923 | Val LogLoss: 0.3920 | Valid Accuracy : 89.4991%\n",
      "âœ… Best model saved (LogLoss: 0.3920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 8/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 8/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 8 | Train Loss: 0.0206 | Val Loss: 0.3898 | Val LogLoss: 0.3896 | Valid Accuracy : 89.8612%\n",
      "âœ… Best model saved (LogLoss: 0.3896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 9/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 9/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 9 | Train Loss: 0.0130 | Val Loss: 0.3864 | Val LogLoss: 0.3864 | Valid Accuracy : 89.7858%\n",
      "âœ… Best model saved (LogLoss: 0.3864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4 Epoch 10/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [06:36<00:00,  1.05it/s]\n",
      "[efficientnet_b4 Epoch 10/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [01:26<00:00,  1.20it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[efficientnet_b4] Epoch 10 | Train Loss: 0.0098 | Val Loss: 0.3802 | Val LogLoss: 0.3802 | Valid Accuracy : 90.1177%\n",
      "âœ… Best model saved (LogLoss: 0.3802)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for backbone_name in models:\n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name = backbone_name).to(device)\n",
    "\n",
    "    print(f\"\\nğŸš€ Training Model: {backbone_name} \\n\\n\")\n",
    "    # ê¸°ì¤€ê°’ ì´ˆê¸°í™”\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    # ì†ì‹¤ í•¨ìˆ˜\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì €\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "    # ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    # í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ \n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # LogLoss\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "                f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "                f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "        \n",
    "        scheduler.step(val_logloss)\n",
    "\n",
    "        # Best model ì €ì¥\n",
    "        \n",
    "        if val_logloss < best_logloss:\n",
    "            best_logloss = val_logloss\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "            print(f\"âœ… Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"ğŸ›‘ Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    del model  # ëª¨ë¸ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¶”ê°€í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ì‘ì„±ì¤‘\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = BaseModel(num_classes=len(class_names), backbone_name='efficientnet_b4').to(device)\n",
    "model.load_state_dict(torch.load('best_efficientnet_b4_epoch10.pth'))\n",
    "backbone_name = 'efficientnet_b4'\n",
    "# ì˜µí‹°ë§ˆì´ì €/ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ì„¤ì •\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "# ì´ì–´ì„œ í•™ìŠµ\n",
    "for epoch in range(10, 20):  # 11~20ì—í¬í¬\n",
    "    print(f\"\\nğŸš€ Training Model: {backbone_name} \\n\\n\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ì¶”ê°€ í•™ìŠµ ì „ ê²€ì¦ ìˆ˜í–‰ìœ¼ë¡œ best_logloss ì´ˆê¸°í™”\n",
    "    model.eval()\n",
    "    val_loss, val_logloss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    best_logloss = val_logloss\n",
    "    no_improve = 0\n",
    "    patience = 5  # patienceë„ ì •ì˜ í•„ìš”\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "            f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "    \n",
    "    scheduler.step(val_logloss)\n",
    "\n",
    "    # Best model ì €ì¥\n",
    "    \n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "        print(f\"âœ… Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"ğŸ›‘ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "del model  # ëª¨ë¸ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ í•´ì œ\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "records = ['best_densenet121_epoch7.pth','best_efficientnet_b3_epoch10.pth',\n",
    "           'best_efficientnet_b4_epoch10.pth','best_resnet101_epoch8.pth']\n",
    "\n",
    "for record in records:\n",
    "    # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n",
    "    parts = record.split('_')\n",
    "# ì˜¬ë°”ë¥¸ ì¡°ê±´ë¬¸\n",
    "    if record in ['best_densenet121_epoch7.pth', 'best_resnet101_epoch8.pth']:\n",
    "        backbone_name = f\"{parts[1]}\"  # densenet121 ë“±\n",
    "    else:\n",
    "        backbone_name = f\"{parts[1]}_{parts[2]}\"  # efficientnet_b3 ë“±\n",
    "    \n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name=backbone_name)\n",
    "    model.load_state_dict(torch.load(record, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # ì¶”ë¡ \n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            for prob in probs.cpu():  # prob: (num_classes,)\n",
    "                result = {\n",
    "                    class_names[i]: prob[i].item()\n",
    "                    for i in range(len(class_names))\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    pred = pd.DataFrame(results)\n",
    "\n",
    "    submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "    \n",
    "    class_columns = submission.columns[1:]\n",
    "    pred.columns = normalize_cols(pred.columns)\n",
    "    class_columns = normalize_cols(class_columns)\n",
    "    pred = pred[class_columns]\n",
    "\n",
    "    submission[class_columns] = pred.values\n",
    "    submission.to_csv(f'{record}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015</th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019</th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024</th>\n",
       "      <th>3008_2á„‰á…¦á„ƒá…¢_2018_2023</th>\n",
       "      <th>3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012</th>\n",
       "      <th>3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022</th>\n",
       "      <th>á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016</th>\n",
       "      <th>á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023</th>\n",
       "      <th>á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022</th>\n",
       "      <th>á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018</th>\n",
       "      <th>á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022</th>\n",
       "      <th>á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.511935e-07</td>\n",
       "      <td>1.445385e-06</td>\n",
       "      <td>1.592065e-07</td>\n",
       "      <td>4.357784e-06</td>\n",
       "      <td>3.298061e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.070755e-07</td>\n",
       "      <td>7.793965e-07</td>\n",
       "      <td>2.955839e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.812796e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.839943e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.176699e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.151721e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.752513e-05</td>\n",
       "      <td>9.487465e-05</td>\n",
       "      <td>1.280151e-04</td>\n",
       "      <td>3.506709e-05</td>\n",
       "      <td>3.918644e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.326350e-04</td>\n",
       "      <td>7.821716e-05</td>\n",
       "      <td>1.066425e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.235167e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.742213e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.497383e-05</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5.077703e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.293226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629503e-05</td>\n",
       "      <td>1.849107e-05</td>\n",
       "      <td>1.507656e-04</td>\n",
       "      <td>6.678894e-06</td>\n",
       "      <td>6.522421e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.378862e-04</td>\n",
       "      <td>1.058777e-05</td>\n",
       "      <td>5.987513e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142872e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.057245e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.381332e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.378176e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.411537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.519213e-06</td>\n",
       "      <td>1.676211e-07</td>\n",
       "      <td>1.582139e-06</td>\n",
       "      <td>5.283350e-07</td>\n",
       "      <td>2.171661e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.027208e-05</td>\n",
       "      <td>3.179571e-06</td>\n",
       "      <td>2.785918e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961595e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.668167e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.549510e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.212071e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.782074e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.922888e-04</td>\n",
       "      <td>5.125251e-03</td>\n",
       "      <td>4.367732e-05</td>\n",
       "      <td>5.357838e-06</td>\n",
       "      <td>1.428535e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.358307e-06</td>\n",
       "      <td>1.325173e-06</td>\n",
       "      <td>5.119073e-05</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.372026e-06</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.196302e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.170576e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.873700e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.729611e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015  1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019  1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024  \\\n",
       "0           7.511935e-07           1.445385e-06           1.592065e-07   \n",
       "1           5.752513e-05           9.487465e-05           1.280151e-04   \n",
       "2           5.629503e-05           1.849107e-05           1.507656e-04   \n",
       "3           3.519213e-06           1.676211e-07           1.582139e-06   \n",
       "4           1.922888e-04           5.125251e-03           4.367732e-05   \n",
       "\n",
       "   2008_2015_2017  2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024  \\\n",
       "0    4.357784e-06                     3.298061e-07   \n",
       "1    3.506709e-05                     3.918644e-05   \n",
       "2    6.678894e-06                     6.522421e-05   \n",
       "3    5.283350e-07                     2.171661e-06   \n",
       "4    5.357838e-06                     1.428535e-05   \n",
       "\n",
       "   2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021  2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024  \\\n",
       "0                              0.000002                          7.070755e-07   \n",
       "1                              0.000038                          6.326350e-04   \n",
       "2                              0.000003                          2.378862e-04   \n",
       "3                              0.000002                          2.027208e-05   \n",
       "4                              0.000098                          1.358307e-06   \n",
       "\n",
       "   3008_2á„‰á…¦á„ƒá…¢_2018_2023  3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012  3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018  ...  \\\n",
       "0          7.793965e-07           2.955839e-07               0.000001  ...   \n",
       "1          7.821716e-05           1.066425e-04               0.000031  ...   \n",
       "2          1.058777e-05           5.987513e-07               0.000010  ...   \n",
       "3          3.179571e-06           2.785918e-06               0.000004  ...   \n",
       "4          1.325173e-06           5.119073e-05               0.000526  ...   \n",
       "\n",
       "   á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022  á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016  á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023  \\\n",
       "0            5.704890e-07            0.000002            8.812796e-07   \n",
       "1            7.235167e-05            0.000015            1.742213e-05   \n",
       "2            1.142872e-05            0.000008            1.057245e-04   \n",
       "3            3.961595e-07            0.000004            3.668167e-05   \n",
       "4            1.372026e-06            0.000060            1.196302e-06   \n",
       "\n",
       "   á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022  á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018  á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022  \\\n",
       "0                0.000001              2.839943e-06               0.000003   \n",
       "1                0.000015              2.497383e-05               0.000106   \n",
       "2                0.000014              2.381332e-05               0.000005   \n",
       "3                0.000008              8.549510e-07               0.000019   \n",
       "4                0.000009              3.170576e-07               0.000004   \n",
       "\n",
       "   á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025  á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018  á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022  \\\n",
       "0          1.176699e-05                  0.000002                  0.000012   \n",
       "1          5.077703e-05                  0.000010                  0.000041   \n",
       "2          1.378176e-05                  0.000003                  0.000029   \n",
       "3          1.212071e-05                  0.000002                  0.000006   \n",
       "4          4.873700e-07                  0.000006                  0.000002   \n",
       "\n",
       "   á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020  \n",
       "0          1.151721e-06  \n",
       "1          1.293226e-05  \n",
       "2          2.411537e-06  \n",
       "3          5.782074e-07  \n",
       "4          6.729611e-06  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F20_2013_2015</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F20_2016_2019</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024</th>\n",
       "      <th>3008_2ì„¸ëŒ€_2018_2023</th>\n",
       "      <th>3ì‹œë¦¬ì¦ˆ_E90_2005_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>í‹°ë³¼ë¦¬_ì—ì–´_2021_2022</th>\n",
       "      <th>íŒŒë‚˜ë©”ë¼_2010_2016</th>\n",
       "      <th>íŒŒë‚˜ë©”ë¼_971_2017_2023</th>\n",
       "      <th>íŒŒì‚¬íŠ¸_GT_B8_2018_2022</th>\n",
       "      <th>íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018</th>\n",
       "      <th>íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022</th>\n",
       "      <th>íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  1ì‹œë¦¬ì¦ˆ_F20_2013_2015  1ì‹œë¦¬ì¦ˆ_F20_2016_2019  1ì‹œë¦¬ì¦ˆ_F40_2020_2024  \\\n",
       "0  TEST_00000                   1                 0.0                 0.0   \n",
       "1  TEST_00001                   1                 0.0                 0.0   \n",
       "2  TEST_00002                   1                 0.0                 0.0   \n",
       "3  TEST_00003                   1                 0.0                 0.0   \n",
       "4  TEST_00004                   1                 0.0                 0.0   \n",
       "\n",
       "   2008_2015_2017  2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024  2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021  \\\n",
       "0             0.0                      0.0                         0.0   \n",
       "1             0.0                      0.0                         0.0   \n",
       "2             0.0                      0.0                         0.0   \n",
       "3             0.0                      0.0                         0.0   \n",
       "4             0.0                      0.0                         0.0   \n",
       "\n",
       "   2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024  3008_2ì„¸ëŒ€_2018_2023  3ì‹œë¦¬ì¦ˆ_E90_2005_2012  ...  \\\n",
       "0                         0.0                 0.0                 0.0  ...   \n",
       "1                         0.0                 0.0                 0.0  ...   \n",
       "2                         0.0                 0.0                 0.0  ...   \n",
       "3                         0.0                 0.0                 0.0  ...   \n",
       "4                         0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   í‹°ë³¼ë¦¬_ì—ì–´_2021_2022  íŒŒë‚˜ë©”ë¼_2010_2016  íŒŒë‚˜ë©”ë¼_971_2017_2023  íŒŒì‚¬íŠ¸_GT_B8_2018_2022  \\\n",
       "0               0.0             0.0                 0.0                  0.0   \n",
       "1               0.0             0.0                 0.0                  0.0   \n",
       "2               0.0             0.0                 0.0                  0.0   \n",
       "3               0.0             0.0                 0.0                  0.0   \n",
       "4               0.0             0.0                 0.0                  0.0   \n",
       "\n",
       "   íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018  íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022  íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025  í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018  \\\n",
       "0                0.0              0.0             0.0                 0.0   \n",
       "1                0.0              0.0             0.0                 0.0   \n",
       "2                0.0              0.0             0.0                 0.0   \n",
       "3                0.0              0.0             0.0                 0.0   \n",
       "4                0.0              0.0             0.0                 0.0   \n",
       "\n",
       "   í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022  í”„ë¦¬ìš°ìŠ¤_C_2018_2020  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1ì‹œë¦¬ì¦ˆ_F20_2013_2015', '1ì‹œë¦¬ì¦ˆ_F20_2016_2019', '1ì‹œë¦¬ì¦ˆ_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024',\n",
      "       '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021', '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024',\n",
      "       '3008_2ì„¸ëŒ€_2018_2023', '3ì‹œë¦¬ì¦ˆ_E90_2005_2012', '3ì‹œë¦¬ì¦ˆ_F30_2013_2018',\n",
      "       ...\n",
      "       'í‹°ë³¼ë¦¬_ì—ì–´_2021_2022', 'íŒŒë‚˜ë©”ë¼_2010_2016', 'íŒŒë‚˜ë©”ë¼_971_2017_2023',\n",
      "       'íŒŒì‚¬íŠ¸_GT_B8_2018_2022', 'íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018', 'íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022',\n",
      "       'íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022',\n",
      "       'í”„ë¦¬ìš°ìŠ¤_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "class_columns = submission.columns[1:]\n",
    "\n",
    "print(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015', '1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019',\n",
      "       '1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024', '2008_2015_2017',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024', '3008_2á„‰á…¦á„ƒá…¢_2018_2023',\n",
      "       '3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012', '3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018',\n",
      "       ...\n",
      "       'á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022', 'á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016',\n",
      "       'á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023', 'á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022',\n",
      "       'á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018', 'á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022',\n",
      "       'á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025', 'á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018',\n",
      "       'á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022', 'á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020'],\n",
      "      dtype='object', length=396)\n",
      "Index(['1ì‹œë¦¬ì¦ˆ_F20_2013_2015', '1ì‹œë¦¬ì¦ˆ_F20_2016_2019', '1ì‹œë¦¬ì¦ˆ_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024',\n",
      "       '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021', '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024',\n",
      "       '3008_2ì„¸ëŒ€_2018_2023', '3ì‹œë¦¬ì¦ˆ_E90_2005_2012', '3ì‹œë¦¬ì¦ˆ_F30_2013_2018',\n",
      "       ...\n",
      "       'í‹°ë³¼ë¦¬_ì—ì–´_2021_2022', 'íŒŒë‚˜ë©”ë¼_2010_2016', 'íŒŒë‚˜ë©”ë¼_971_2017_2023',\n",
      "       'íŒŒì‚¬íŠ¸_GT_B8_2018_2022', 'íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018', 'íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022',\n",
      "       'íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022',\n",
      "       'í”„ë¦¬ìš°ìŠ¤_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "print(pred.columns)\n",
    "print(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ëª…ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "if list(pred.columns) == list(class_columns):\n",
    "    print(\"ì»¬ëŸ¼ëª…ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì»¬ëŸ¼ëª…ì´ ë‹¤ë¦…ë‹ˆë‹¤!\")\n",
    "    print(\"predì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:\", set(pred.columns) - set(class_columns))\n",
    "    print(\"class_columnsì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:\", set(class_columns) - set(pred.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEtric = LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "\n",
    "def multiclass_log_loss(answer_df, submission_df):\n",
    "    class_list = sorted(answer_df['label'].unique())\n",
    "    \n",
    "    if submission_df.shape[0] != answer_df.shape[0]:\n",
    "        raise ValueError(\"submission_df í–‰ ê°œìˆ˜ê°€ answer_dfì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    if not all(answer_df['ID'] == submission_df['ID']):\n",
    "        raise ValueError(\"IDê°€ ì •ë ¬ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    missing_cols = [col for col in class_list if col not in submission_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"í´ë˜ìŠ¤ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}\")\n",
    "    \n",
    "    if submission_df[class_list].isnull().any().any():\n",
    "        raise ValueError(\"NaN í¬í•¨ë¨\")\n",
    "    for col in class_list:\n",
    "        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():\n",
    "            raise ValueError(f\"{col}ì˜ í™•ë¥ ê°’ì´ 0~1 ë²”ìœ„ ì´ˆê³¼\")\n",
    "\n",
    "    # ì •ë‹µ ì¸ë±ìŠ¤ ë³€í™˜\n",
    "    true_labels = answer_df['label'].tolist()\n",
    "    true_idx = [class_list.index(lbl) for lbl in true_labels]\n",
    "\n",
    "    # í™•ë¥  ì •ê·œí™” + clip\n",
    "    probs = submission_df[class_list].values\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° (í´ë˜ìŠ¤ 3ê°œ: A, B, C)\n",
    "answer_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'label': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'A': [0.7, 0.1, 0.2],\n",
    "    'B': [0.2, 0.8, 0.3],\n",
    "    'C': [0.1, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "loss = multiclass_log_loss(answer_df, submission_df)\n",
    "print(f\"Log Loss: {loss:.6f}\") # Log Loss: 0.424322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
