{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as tv_models\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import unicodedata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 20,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mseed_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSEED\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mseed_everything\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(seed)\n\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    121\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    122\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 229\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    121\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed Í≥†Ï†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # ÌÖåÏä§Ìä∏ÏÖã: ÎùºÎ≤® ÏóÜÏù¥ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎßå Ï†ÄÏû•\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # ÌïôÏäµÏÖã: ÌÅ¥ÎûòÏä§Î≥Ñ Ìè¥Îçî Íµ¨Ï°∞ÏóêÏÑú ÎùºÎ≤® Ï∂îÏ∂ú\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = '../data/train'\n",
    "test_root = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # PIL.ImageÏóê Ï†ÅÏö©\n",
    "    transforms.ToTensor(),  # Ïó¨Í∏∞ÍπåÏßÄÎäî PIL.Image Î≥ÄÌôò\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),  # TensorÏóê Ï†ÅÏö©\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30Í∞ú Îç∞Ïù¥ÌÑ∞ÏÖãÎßå ÏÉòÌîåÎßÅÌï¥ÏÑú Ïã§Ìóò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞: 33137\n",
      "ÏÑ†ÌÉù ÌÅ¥ÎûòÏä§ Ïàò: 30\n",
      "ÏÑ†ÌÉù ÏÉòÌîå Ïàò: 2474\n",
      "ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: 1979, Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: 495\n"
     ]
    }
   ],
   "source": [
    "# Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞: {len(full_dataset)}\")\n",
    "\n",
    "# 1. 30Í∞ú ÌÅ¥ÎûòÏä§ Î¨¥ÏûëÏúÑ ÏÑ†ÌÉù\n",
    "all_classes = full_dataset.classes\n",
    "np.random.seed(42)  # Ïû¨ÌòÑÏÑ± Î≥¥Ïû•\n",
    "selected_classes = np.random.choice(all_classes, size=30, replace=False)\n",
    "\n",
    "# 2. ÏÑ†ÌÉùÎêú ÌÅ¥ÎûòÏä§Ïùò Ïù∏Îç±Ïä§ Ï∂îÏ∂ú\n",
    "selected_class_indices = [full_dataset.class_to_idx[cls] for cls in selected_classes]\n",
    "\n",
    "# 3. ÏÑ†ÌÉùÎêú ÌÅ¥ÎûòÏä§Ïóê Ìï¥ÎãπÌïòÎäî ÏÉòÌîå Ïù∏Îç±Ïä§ Ï∂îÏ∂ú\n",
    "selected_sample_indices = [\n",
    "    i for i, (_, label) in enumerate(full_dataset.samples) \n",
    "    if label in selected_class_indices\n",
    "]\n",
    "\n",
    "# 4. ÏÑ†ÌÉùÎêú ÏÉòÌîåÏùò ÎùºÎ≤® Ï∂îÏ∂ú (stratified splitÏùÑ ÏúÑÌï¥)\n",
    "selected_labels = [full_dataset.samples[i][1] for i in selected_sample_indices]\n",
    "\n",
    "# 5. Stratified Split ÏàòÌñâ (80:20 ÎπÑÏú®)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    selected_sample_indices,\n",
    "    test_size=0.2,\n",
    "    stratify=selected_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. ÏÑúÎ∏åÏÖã ÏÉùÏÑ± (Ìä∏ÎûúÏä§Ìè¨Î©îÏù¥ÏÖò Ï†ÅÏö©)\n",
    "train_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=train_transform), \n",
    "    train_idx\n",
    ")\n",
    "val_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=val_transform), \n",
    "    val_idx\n",
    ")\n",
    "\n",
    "print(f\"ÏÑ†ÌÉù ÌÅ¥ÎûòÏä§ Ïàò: {len(selected_classes)}\")\n",
    "print(f\"ÏÑ†ÌÉù ÏÉòÌîå Ïàò: {len(selected_sample_indices)}\")\n",
    "print(f\"ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {len(train_dataset)}, Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {len(val_dataset)}\")\n",
    "class_names = selected_classes\n",
    "\n",
    "# 7. DataLoader ÏÉùÏÑ±\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÏõêÎ≥∏ - ÏãúÍ∞ÑÏù¥ ÎÑàÎ¨¥ Ïò§Î†§ Í±∏Î†§ÏÑú ÏúÑÏóê 30Í∞ú ÏÉòÌîåÎ°ú Ïã§ÌóòÌï† Í≤É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: 33137\n",
      "train Ïù¥ÎØ∏ÏßÄ Ïàò: 26509, valid Ïù¥ÎØ∏ÏßÄ Ïàò: 6628\n"
     ]
    }
   ],
   "source": [
    "# Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform Í∞ÅÍ∞Å Ï†ÅÏö©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train Ïù¥ÎØ∏ÏßÄ Ïàò: {len(train_dataset)}, valid Ïù¥ÎØ∏ÏßÄ Ïàò: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader Ï†ïÏùò\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseModel Define : resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = tv_models.resnet18(pretrained=True)  # ResNet18 Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractorÎ°úÎßå ÏÇ¨Ïö©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # Î∂ÑÎ•òÍ∏∞\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = BaseModel(num_classes=len(class_names)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base4model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone_name='resnet18', pretrained=True):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if self.backbone_name.startswith('resnet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            self.backbone = timm.create_model(self.backbone_name, pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        # DenseNet ÏßÄÏõê Ï∂îÍ∞Ä!\n",
    "        elif self.backbone_name.startswith('densenet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî backbone: {backbone_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.head(features)\n",
    "        return out\n",
    "    \n",
    "# Ïó¨Í∏∞ Î™®Îç∏ÏóêÏÑú Î∞òÎ≥µÎ¨∏ÏúºÎ°ú ÎèåÎ¶¨Í∏∞.\n",
    "models = [\n",
    "    'resnet18',\n",
    "    'densenet121',\n",
    "    'resnet101',         # Ï∂îÍ∞Ä Ï∂îÏ≤ú!\n",
    "    'efficientnet_b3',\n",
    "    'efficientnet_b4',\n",
    "    # 'densenet121',     # Î≥¥ÎÑàÏä§Î°ú Ï∂îÍ∞ÄÌï¥ÎèÑ Ï¢ãÏùå\n",
    "    # 'vit_base_patch16_224',  # ÏµúÏã† Ìä∏Î†åÎìú Ïã§ÌóòÏö©\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m backbone_name \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mBaseModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müöÄ Training Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Í∏∞Ï§ÄÍ∞í Ï¥àÍ∏∞Ìôî\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for backbone_name in models:\n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name = backbone_name).to(device)\n",
    "\n",
    "    print(f\"\\nüöÄ Training Model: {backbone_name} \\n\\n\")\n",
    "    # Í∏∞Ï§ÄÍ∞í Ï¥àÍ∏∞Ìôî\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    # ÏÜêÏã§ Ìï®Ïàò\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ÏòµÌã∞ÎßàÏù¥Ï†Ä\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "    # Ïä§ÏºÄÏ§ÑÎü¨\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    # ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Î£®ÌîÑ \n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # LogLoss\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "        # Í≤∞Í≥º Ï∂úÎ†•\n",
    "        print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "                f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "                f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "        \n",
    "        scheduler.step(val_logloss)\n",
    "\n",
    "        # Best model Ï†ÄÏû•\n",
    "        \n",
    "        if val_logloss < best_logloss:\n",
    "            best_logloss = val_logloss\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "            print(f\"‚úÖ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"üõë Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    del model  # Î™®Îç∏ ÌïôÏäµ ÌõÑ Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ï∂îÍ∞ÄÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ÏûëÏÑ±Ï§ë\n",
    "\n",
    "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "model = BaseModel(num_classes=len(class_names), backbone_name='efficientnet_b4').to(device)\n",
    "model.load_state_dict(torch.load('best_efficientnet_b4_epoch10.pth'))\n",
    "backbone_name = 'efficientnet_b4'\n",
    "# ÏòµÌã∞ÎßàÏù¥Ï†Ä/Ïä§ÏºÄÏ§ÑÎü¨ Ïû¨ÏÑ§Ï†ï\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "# Ïù¥Ïñ¥ÏÑú ÌïôÏäµ\n",
    "for epoch in range(10, 20):  # 11~20ÏóêÌè¨ÌÅ¨\n",
    "    print(f\"\\nüöÄ Training Model: {backbone_name} \\n\\n\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Ï∂îÍ∞Ä ÌïôÏäµ Ï†Ñ Í≤ÄÏ¶ù ÏàòÌñâÏúºÎ°ú best_logloss Ï¥àÍ∏∞Ìôî\n",
    "    model.eval()\n",
    "    val_loss, val_logloss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    best_logloss = val_logloss\n",
    "    no_improve = 0\n",
    "    patience = 5  # patienceÎèÑ Ï†ïÏùò ÌïÑÏöî\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # Í≤∞Í≥º Ï∂úÎ†•\n",
    "    print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "            f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "    \n",
    "    scheduler.step(val_logloss)\n",
    "\n",
    "    # Best model Ï†ÄÏû•\n",
    "    \n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "        print(f\"‚úÖ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"üõë Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "del model  # Î™®Îç∏ ÌïôÏäµ ÌõÑ Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "# records = ['best_densenet121_epoch7.pth','best_efficientnet_b3_epoch10.pth',\n",
    "        #    'best_efficientnet_b4_epoch10.pth','best_resnet101_epoch8.pth']\n",
    "records = ['best_resnet18_epoch17.pth']\n",
    "for record in records:\n",
    "    # Ï†ÄÏû•Îêú Î™®Îç∏ Î°úÎìú\n",
    "    parts = record.split('_')\n",
    "# Ïò¨Î∞îÎ•∏ Ï°∞Í±¥Î¨∏\n",
    "    if record in ['best_resnet18_epoch17.pth', 'best_resnet101_epoch8.pth']:\n",
    "        backbone_name = f\"{parts[1]}\"  # densenet121 Îì±\n",
    "    else:\n",
    "        backbone_name = f\"{parts[1]}_{parts[2]}\"  # efficientnet_b3 Îì±\n",
    "    \n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name=backbone_name)\n",
    "    model.load_state_dict(torch.load(record, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # Ï∂îÎ°†\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Í∞Å Î∞∞ÏπòÏùò ÌôïÎ•†ÏùÑ Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "            for prob in probs.cpu():  # prob: (num_classes,)\n",
    "                result = {\n",
    "                    class_names[i]: prob[i].item()\n",
    "                    for i in range(len(class_names))\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    pred = pd.DataFrame(results)\n",
    "\n",
    "    submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # 'ID' Ïª¨ÎüºÏùÑ Ï†úÏô∏Ìïú ÌÅ¥ÎûòÏä§ Ïª¨Îüº Ï†ïÎ†¨\n",
    "    \n",
    "    class_columns = submission.columns[1:]\n",
    "    pred.columns = normalize_cols(pred.columns)\n",
    "    class_columns = normalize_cols(class_columns)\n",
    "    pred = pred[class_columns]\n",
    "\n",
    "    submission[class_columns] = pred.values\n",
    "    submission.to_csv(f'{record}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2013_2015</th>\n",
       "      <th>1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2016_2019</th>\n",
       "      <th>1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·ÑÄ·Ö≥·ÑÖ·Ö°·Ü´·Ñè·ÖÆ·Ñë·Ö¶_F44_2020_2024</th>\n",
       "      <th>2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_F45_2019_2021</th>\n",
       "      <th>2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_U06_2022_2024</th>\n",
       "      <th>3008_2·Ñâ·Ö¶·ÑÉ·Ö¢_2018_2023</th>\n",
       "      <th>3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_E90_2005_2012</th>\n",
       "      <th>3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F30_2013_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>·Ñê·Öµ·Ñá·Ö©·ÜØ·ÑÖ·Öµ_·Ñã·Ö¶·Ñã·Ö•_2021_2022</th>\n",
       "      <th>·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_2010_2016</th>\n",
       "      <th>·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_971_2017_2023</th>\n",
       "      <th>·Ñë·Ö°·Ñâ·Ö°·Ñê·Ö≥_GT_B8_2018_2022</th>\n",
       "      <th>·Ñë·Ö°·Ñã·Öµ·ÜØ·ÑÖ·Ö•·Ü∫_3·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018</th>\n",
       "      <th>·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_2019_2022</th>\n",
       "      <th>·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_LX3_2025</th>\n",
       "      <th>·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018</th>\n",
       "      <th>·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2019_2022</th>\n",
       "      <th>·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.511935e-07</td>\n",
       "      <td>1.445385e-06</td>\n",
       "      <td>1.592065e-07</td>\n",
       "      <td>4.357784e-06</td>\n",
       "      <td>3.298061e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.070755e-07</td>\n",
       "      <td>7.793965e-07</td>\n",
       "      <td>2.955839e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.812796e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.839943e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.176699e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.151721e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.752513e-05</td>\n",
       "      <td>9.487465e-05</td>\n",
       "      <td>1.280151e-04</td>\n",
       "      <td>3.506709e-05</td>\n",
       "      <td>3.918644e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.326350e-04</td>\n",
       "      <td>7.821716e-05</td>\n",
       "      <td>1.066425e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.235167e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.742213e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.497383e-05</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5.077703e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.293226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629503e-05</td>\n",
       "      <td>1.849107e-05</td>\n",
       "      <td>1.507656e-04</td>\n",
       "      <td>6.678894e-06</td>\n",
       "      <td>6.522421e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.378862e-04</td>\n",
       "      <td>1.058777e-05</td>\n",
       "      <td>5.987513e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142872e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.057245e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.381332e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.378176e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.411537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.519213e-06</td>\n",
       "      <td>1.676211e-07</td>\n",
       "      <td>1.582139e-06</td>\n",
       "      <td>5.283350e-07</td>\n",
       "      <td>2.171661e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.027208e-05</td>\n",
       "      <td>3.179571e-06</td>\n",
       "      <td>2.785918e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961595e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.668167e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.549510e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.212071e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.782074e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.922888e-04</td>\n",
       "      <td>5.125251e-03</td>\n",
       "      <td>4.367732e-05</td>\n",
       "      <td>5.357838e-06</td>\n",
       "      <td>1.428535e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.358307e-06</td>\n",
       "      <td>1.325173e-06</td>\n",
       "      <td>5.119073e-05</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.372026e-06</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.196302e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.170576e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.873700e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.729611e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2013_2015  1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2016_2019  1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F40_2020_2024  \\\n",
       "0           7.511935e-07           1.445385e-06           1.592065e-07   \n",
       "1           5.752513e-05           9.487465e-05           1.280151e-04   \n",
       "2           5.629503e-05           1.849107e-05           1.507656e-04   \n",
       "3           3.519213e-06           1.676211e-07           1.582139e-06   \n",
       "4           1.922888e-04           5.125251e-03           4.367732e-05   \n",
       "\n",
       "   2008_2015_2017  2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·ÑÄ·Ö≥·ÑÖ·Ö°·Ü´·Ñè·ÖÆ·Ñë·Ö¶_F44_2020_2024  \\\n",
       "0    4.357784e-06                     3.298061e-07   \n",
       "1    3.506709e-05                     3.918644e-05   \n",
       "2    6.678894e-06                     6.522421e-05   \n",
       "3    5.283350e-07                     2.171661e-06   \n",
       "4    5.357838e-06                     1.428535e-05   \n",
       "\n",
       "   2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_F45_2019_2021  2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_U06_2022_2024  \\\n",
       "0                              0.000002                          7.070755e-07   \n",
       "1                              0.000038                          6.326350e-04   \n",
       "2                              0.000003                          2.378862e-04   \n",
       "3                              0.000002                          2.027208e-05   \n",
       "4                              0.000098                          1.358307e-06   \n",
       "\n",
       "   3008_2·Ñâ·Ö¶·ÑÉ·Ö¢_2018_2023  3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_E90_2005_2012  3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F30_2013_2018  ...  \\\n",
       "0          7.793965e-07           2.955839e-07               0.000001  ...   \n",
       "1          7.821716e-05           1.066425e-04               0.000031  ...   \n",
       "2          1.058777e-05           5.987513e-07               0.000010  ...   \n",
       "3          3.179571e-06           2.785918e-06               0.000004  ...   \n",
       "4          1.325173e-06           5.119073e-05               0.000526  ...   \n",
       "\n",
       "   ·Ñê·Öµ·Ñá·Ö©·ÜØ·ÑÖ·Öµ_·Ñã·Ö¶·Ñã·Ö•_2021_2022  ·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_2010_2016  ·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_971_2017_2023  \\\n",
       "0            5.704890e-07            0.000002            8.812796e-07   \n",
       "1            7.235167e-05            0.000015            1.742213e-05   \n",
       "2            1.142872e-05            0.000008            1.057245e-04   \n",
       "3            3.961595e-07            0.000004            3.668167e-05   \n",
       "4            1.372026e-06            0.000060            1.196302e-06   \n",
       "\n",
       "   ·Ñë·Ö°·Ñâ·Ö°·Ñê·Ö≥_GT_B8_2018_2022  ·Ñë·Ö°·Ñã·Öµ·ÜØ·ÑÖ·Ö•·Ü∫_3·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018  ·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_2019_2022  \\\n",
       "0                0.000001              2.839943e-06               0.000003   \n",
       "1                0.000015              2.497383e-05               0.000106   \n",
       "2                0.000014              2.381332e-05               0.000005   \n",
       "3                0.000008              8.549510e-07               0.000019   \n",
       "4                0.000009              3.170576e-07               0.000004   \n",
       "\n",
       "   ·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_LX3_2025  ·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018  ·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2019_2022  \\\n",
       "0          1.176699e-05                  0.000002                  0.000012   \n",
       "1          5.077703e-05                  0.000010                  0.000041   \n",
       "2          1.378176e-05                  0.000003                  0.000029   \n",
       "3          1.212071e-05                  0.000002                  0.000006   \n",
       "4          4.873700e-07                  0.000006                  0.000002   \n",
       "\n",
       "   ·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_C_2018_2020  \n",
       "0          1.151721e-06  \n",
       "1          1.293226e-05  \n",
       "2          2.411537e-06  \n",
       "3          5.782074e-07  \n",
       "4          6.729611e-06  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1ÏãúÎ¶¨Ï¶à_F20_2013_2015</th>\n",
       "      <th>1ÏãúÎ¶¨Ï¶à_F20_2016_2019</th>\n",
       "      <th>1ÏãúÎ¶¨Ï¶à_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2ÏãúÎ¶¨Ï¶à_Í∑∏ÎûÄÏø†Ìéò_F44_2020_2024</th>\n",
       "      <th>2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_F45_2019_2021</th>\n",
       "      <th>2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_U06_2022_2024</th>\n",
       "      <th>3008_2ÏÑ∏ÎåÄ_2018_2023</th>\n",
       "      <th>3ÏãúÎ¶¨Ï¶à_E90_2005_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>Ìã∞Î≥ºÎ¶¨_ÏóêÏñ¥_2021_2022</th>\n",
       "      <th>ÌååÎÇòÎ©îÎùº_2010_2016</th>\n",
       "      <th>ÌååÎÇòÎ©îÎùº_971_2017_2023</th>\n",
       "      <th>ÌååÏÇ¨Ìä∏_GT_B8_2018_2022</th>\n",
       "      <th>ÌååÏùºÎüø_3ÏÑ∏ÎåÄ_2016_2018</th>\n",
       "      <th>Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_2019_2022</th>\n",
       "      <th>Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_LX3_2025</th>\n",
       "      <th>ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2016_2018</th>\n",
       "      <th>ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2019_2022</th>\n",
       "      <th>ÌîÑÎ¶¨Ïö∞Ïä§_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  1ÏãúÎ¶¨Ï¶à_F20_2013_2015  1ÏãúÎ¶¨Ï¶à_F20_2016_2019  1ÏãúÎ¶¨Ï¶à_F40_2020_2024  \\\n",
       "0  TEST_00000                   1                 0.0                 0.0   \n",
       "1  TEST_00001                   1                 0.0                 0.0   \n",
       "2  TEST_00002                   1                 0.0                 0.0   \n",
       "3  TEST_00003                   1                 0.0                 0.0   \n",
       "4  TEST_00004                   1                 0.0                 0.0   \n",
       "\n",
       "   2008_2015_2017  2ÏãúÎ¶¨Ï¶à_Í∑∏ÎûÄÏø†Ìéò_F44_2020_2024  2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_F45_2019_2021  \\\n",
       "0             0.0                      0.0                         0.0   \n",
       "1             0.0                      0.0                         0.0   \n",
       "2             0.0                      0.0                         0.0   \n",
       "3             0.0                      0.0                         0.0   \n",
       "4             0.0                      0.0                         0.0   \n",
       "\n",
       "   2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_U06_2022_2024  3008_2ÏÑ∏ÎåÄ_2018_2023  3ÏãúÎ¶¨Ï¶à_E90_2005_2012  ...  \\\n",
       "0                         0.0                 0.0                 0.0  ...   \n",
       "1                         0.0                 0.0                 0.0  ...   \n",
       "2                         0.0                 0.0                 0.0  ...   \n",
       "3                         0.0                 0.0                 0.0  ...   \n",
       "4                         0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   Ìã∞Î≥ºÎ¶¨_ÏóêÏñ¥_2021_2022  ÌååÎÇòÎ©îÎùº_2010_2016  ÌååÎÇòÎ©îÎùº_971_2017_2023  ÌååÏÇ¨Ìä∏_GT_B8_2018_2022  \\\n",
       "0               0.0             0.0                 0.0                  0.0   \n",
       "1               0.0             0.0                 0.0                  0.0   \n",
       "2               0.0             0.0                 0.0                  0.0   \n",
       "3               0.0             0.0                 0.0                  0.0   \n",
       "4               0.0             0.0                 0.0                  0.0   \n",
       "\n",
       "   ÌååÏùºÎüø_3ÏÑ∏ÎåÄ_2016_2018  Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_2019_2022  Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_LX3_2025  ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2016_2018  \\\n",
       "0                0.0              0.0             0.0                 0.0   \n",
       "1                0.0              0.0             0.0                 0.0   \n",
       "2                0.0              0.0             0.0                 0.0   \n",
       "3                0.0              0.0             0.0                 0.0   \n",
       "4                0.0              0.0             0.0                 0.0   \n",
       "\n",
       "   ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2019_2022  ÌîÑÎ¶¨Ïö∞Ïä§_C_2018_2020  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1ÏãúÎ¶¨Ï¶à_F20_2013_2015', '1ÏãúÎ¶¨Ï¶à_F20_2016_2019', '1ÏãúÎ¶¨Ï¶à_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ÏãúÎ¶¨Ï¶à_Í∑∏ÎûÄÏø†Ìéò_F44_2020_2024',\n",
      "       '2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_F45_2019_2021', '2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_U06_2022_2024',\n",
      "       '3008_2ÏÑ∏ÎåÄ_2018_2023', '3ÏãúÎ¶¨Ï¶à_E90_2005_2012', '3ÏãúÎ¶¨Ï¶à_F30_2013_2018',\n",
      "       ...\n",
      "       'Ìã∞Î≥ºÎ¶¨_ÏóêÏñ¥_2021_2022', 'ÌååÎÇòÎ©îÎùº_2010_2016', 'ÌååÎÇòÎ©îÎùº_971_2017_2023',\n",
      "       'ÌååÏÇ¨Ìä∏_GT_B8_2018_2022', 'ÌååÏùºÎüø_3ÏÑ∏ÎåÄ_2016_2018', 'Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_2019_2022',\n",
      "       'Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_LX3_2025', 'ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2016_2018', 'ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2019_2022',\n",
      "       'ÌîÑÎ¶¨Ïö∞Ïä§_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "class_columns = submission.columns[1:]\n",
    "\n",
    "print(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2013_2015', '1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F20_2016_2019',\n",
      "       '1·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F40_2020_2024', '2008_2015_2017',\n",
      "       '2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·ÑÄ·Ö≥·ÑÖ·Ö°·Ü´·Ñè·ÖÆ·Ñë·Ö¶_F44_2020_2024',\n",
      "       '2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_F45_2019_2021',\n",
      "       '2·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_·Ñã·Ö¢·Ü®·Ñê·Öµ·Ñá·Ö≥_·Ñê·ÖÆ·Ñã·Ö•·ÑÖ·Ö•_U06_2022_2024', '3008_2·Ñâ·Ö¶·ÑÉ·Ö¢_2018_2023',\n",
      "       '3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_E90_2005_2012', '3·Ñâ·Öµ·ÑÖ·Öµ·Ñå·Ö≥_F30_2013_2018',\n",
      "       ...\n",
      "       '·Ñê·Öµ·Ñá·Ö©·ÜØ·ÑÖ·Öµ_·Ñã·Ö¶·Ñã·Ö•_2021_2022', '·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_2010_2016',\n",
      "       '·Ñë·Ö°·ÑÇ·Ö°·ÑÜ·Ö¶·ÑÖ·Ö°_971_2017_2023', '·Ñë·Ö°·Ñâ·Ö°·Ñê·Ö≥_GT_B8_2018_2022',\n",
      "       '·Ñë·Ö°·Ñã·Öµ·ÜØ·ÑÖ·Ö•·Ü∫_3·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018', '·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_2019_2022',\n",
      "       '·Ñë·Ö¢·ÜØ·ÑÖ·Öµ·Ñâ·Ö¶·Ñã·Öµ·ÑÉ·Ö≥_LX3_2025', '·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2016_2018',\n",
      "       '·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_4·Ñâ·Ö¶·ÑÉ·Ö¢_2019_2022', '·Ñë·Ö≥·ÑÖ·Öµ·Ñã·ÖÆ·Ñâ·Ö≥_C_2018_2020'],\n",
      "      dtype='object', length=396)\n",
      "Index(['1ÏãúÎ¶¨Ï¶à_F20_2013_2015', '1ÏãúÎ¶¨Ï¶à_F20_2016_2019', '1ÏãúÎ¶¨Ï¶à_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ÏãúÎ¶¨Ï¶à_Í∑∏ÎûÄÏø†Ìéò_F44_2020_2024',\n",
      "       '2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_F45_2019_2021', '2ÏãúÎ¶¨Ï¶à_Ïï°Ìã∞Î∏å_Ìà¨Ïñ¥Îü¨_U06_2022_2024',\n",
      "       '3008_2ÏÑ∏ÎåÄ_2018_2023', '3ÏãúÎ¶¨Ï¶à_E90_2005_2012', '3ÏãúÎ¶¨Ï¶à_F30_2013_2018',\n",
      "       ...\n",
      "       'Ìã∞Î≥ºÎ¶¨_ÏóêÏñ¥_2021_2022', 'ÌååÎÇòÎ©îÎùº_2010_2016', 'ÌååÎÇòÎ©îÎùº_971_2017_2023',\n",
      "       'ÌååÏÇ¨Ìä∏_GT_B8_2018_2022', 'ÌååÏùºÎüø_3ÏÑ∏ÎåÄ_2016_2018', 'Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_2019_2022',\n",
      "       'Ìå∞Î¶¨ÏÑ∏Ïù¥Îìú_LX3_2025', 'ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2016_2018', 'ÌîÑÎ¶¨Ïö∞Ïä§_4ÏÑ∏ÎåÄ_2019_2022',\n",
      "       'ÌîÑÎ¶¨Ïö∞Ïä§_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "print(pred.columns)\n",
    "print(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïª¨ÎüºÎ™ÖÏù¥ ÏôÑÏ†ÑÌûà ÏùºÏπòÌï©ÎãàÎã§!\n"
     ]
    }
   ],
   "source": [
    "if list(pred.columns) == list(class_columns):\n",
    "    print(\"Ïª¨ÎüºÎ™ÖÏù¥ ÏôÑÏ†ÑÌûà ÏùºÏπòÌï©ÎãàÎã§!\")\n",
    "else:\n",
    "    print(\"Ïª¨ÎüºÎ™ÖÏù¥ Îã§Î¶ÖÎãàÎã§!\")\n",
    "    print(\"predÏóêÎßå ÏûàÎäî Ïª¨Îüº:\", set(pred.columns) - set(class_columns))\n",
    "    print(\"class_columnsÏóêÎßå ÏûàÎäî Ïª¨Îüº:\", set(class_columns) - set(pred.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' Ïª¨ÎüºÏùÑ Ï†úÏô∏Ìïú ÌÅ¥ÎûòÏä§ Ïª¨Îüº Ï†ïÎ†¨\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEtric = LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "\n",
    "def multiclass_log_loss(answer_df, submission_df):\n",
    "    class_list = sorted(answer_df['label'].unique())\n",
    "    \n",
    "    if submission_df.shape[0] != answer_df.shape[0]:\n",
    "        raise ValueError(\"submission_df Ìñâ Í∞úÏàòÍ∞Ä answer_dfÏôÄ ÏùºÏπòÌïòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
    "\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    if not all(answer_df['ID'] == submission_df['ID']):\n",
    "        raise ValueError(\"IDÍ∞Ä Ï†ïÎ†¨ÎêòÏßÄ ÏïäÏïòÍ±∞ÎÇò Î∂àÏùºÏπòÌï©ÎãàÎã§.\")\n",
    "    \n",
    "    missing_cols = [col for col in class_list if col not in submission_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"ÌÅ¥ÎûòÏä§ Ïª¨Îüº ÎàÑÎùΩ: {missing_cols}\")\n",
    "    \n",
    "    if submission_df[class_list].isnull().any().any():\n",
    "        raise ValueError(\"NaN Ìè¨Ìï®Îê®\")\n",
    "    for col in class_list:\n",
    "        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():\n",
    "            raise ValueError(f\"{col}Ïùò ÌôïÎ•†Í∞íÏù¥ 0~1 Î≤îÏúÑ Ï¥àÍ≥º\")\n",
    "\n",
    "    # Ï†ïÎãµ Ïù∏Îç±Ïä§ Î≥ÄÌôò\n",
    "    true_labels = answer_df['label'].tolist()\n",
    "    true_idx = [class_list.index(lbl) for lbl in true_labels]\n",
    "\n",
    "    # ÌôïÎ•† Ï†ïÍ∑úÌôî + clip\n",
    "    probs = submission_df[class_list].values\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))\n",
    "\n",
    "# ÏòàÏãú Îç∞Ïù¥ÌÑ∞ (ÌÅ¥ÎûòÏä§ 3Í∞ú: A, B, C)\n",
    "answer_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'label': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'A': [0.7, 0.1, 0.2],\n",
    "    'B': [0.2, 0.8, 0.3],\n",
    "    'C': [0.1, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# Ìï®Ïàò Ïã§Ìñâ\n",
    "loss = multiclass_log_loss(answer_df, submission_df)\n",
    "print(f\"Log Loss: {loss:.6f}\") # Log Loss: 0.424322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
