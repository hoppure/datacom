{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as tv_models\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import unicodedata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 40,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = '../data/train'\n",
    "test_root = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    # transforms.RandomSolarize(threshold=192.0, p=0.1),\n",
    "    transforms.RandomInvert(p=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "'''\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # PIL.Imageì— ì ìš©\n",
    "    transforms.ToTensor(),  # ì—¬ê¸°ê¹Œì§€ëŠ” PIL.Image ë³€í™˜\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),  # Tensorì— ì ìš©\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "'''\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30ê°œ ë°ì´í„°ì…‹ë§Œ ìƒ˜í”Œë§í•´ì„œ ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë°ì´í„°ì…‹ í¬ê¸°: 33137\n",
      "ì„ íƒ í´ë˜ìŠ¤ ìˆ˜: 30\n",
      "ì„ íƒ ìƒ˜í”Œ ìˆ˜: 2474\n",
      "í•™ìŠµ ë°ì´í„° í¬ê¸°: 1979, ê²€ì¦ ë°ì´í„° í¬ê¸°: 495\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ì›ë³¸ ë°ì´í„°ì…‹ í¬ê¸°: {len(full_dataset)}\")\n",
    "\n",
    "# 1. 30ê°œ í´ë˜ìŠ¤ ë¬´ì‘ìœ„ ì„ íƒ\n",
    "all_classes = full_dataset.classes\n",
    "np.random.seed(42)  # ì¬í˜„ì„± ë³´ì¥\n",
    "selected_classes = np.random.choice(all_classes, size=30, replace=False)\n",
    "\n",
    "# 2. ì„ íƒëœ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "selected_class_indices = [full_dataset.class_to_idx[cls] for cls in selected_classes]\n",
    "\n",
    "# 3. ì„ íƒëœ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "selected_sample_indices = [\n",
    "    i for i, (_, label) in enumerate(full_dataset.samples) \n",
    "    if label in selected_class_indices\n",
    "]\n",
    "\n",
    "# 4. ì„ íƒëœ ìƒ˜í”Œì˜ ë¼ë²¨ ì¶”ì¶œ (stratified splitì„ ìœ„í•´)\n",
    "selected_labels = [full_dataset.samples[i][1] for i in selected_sample_indices]\n",
    "\n",
    "# 5. Stratified Split ìˆ˜í–‰ (80:20 ë¹„ìœ¨)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    selected_sample_indices,\n",
    "    test_size=0.2,\n",
    "    stratify=selected_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. ì„œë¸Œì…‹ ìƒì„± (íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì ìš©)\n",
    "train_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=train_transform), \n",
    "    train_idx\n",
    ")\n",
    "val_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=val_transform), \n",
    "    val_idx\n",
    ")\n",
    "\n",
    "print(f\"ì„ íƒ í´ë˜ìŠ¤ ìˆ˜: {len(selected_classes)}\")\n",
    "print(f\"ì„ íƒ ìƒ˜í”Œ ìˆ˜: {len(selected_sample_indices)}\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„° í¬ê¸°: {len(train_dataset)}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {len(val_dataset)}\")\n",
    "\n",
    "# 7. DataLoader ìƒì„±\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì›ë³¸ - ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë ¤ ê±¸ë ¤ì„œ ìœ„ì— 30ê°œ ìƒ˜í”Œë¡œ ì‹¤í—˜í•  ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 33137\n",
      "train ì´ë¯¸ì§€ ìˆ˜: 26509, valid ì´ë¯¸ì§€ ìˆ˜: 6628\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform ê°ê° ì ìš©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseModel Define : resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = tv_models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = BaseModel(num_classes=len(class_names)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base4model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone_name='resnet18', pretrained=True):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if self.backbone_name.startswith('resnet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            self.backbone = timm.create_model(self.backbone_name, pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        # DenseNet ì§€ì› ì¶”ê°€!\n",
    "        elif self.backbone_name.startswith('densenet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” backbone: {backbone_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.head(features)\n",
    "        return out\n",
    "    \n",
    "# ì—¬ê¸° ëª¨ë¸ì—ì„œ ë°˜ë³µë¬¸ìœ¼ë¡œ ëŒë¦¬ê¸°.\n",
    "models = [\n",
    "    'resnet18',\n",
    "    'densenet121',\n",
    "    'resnet101',         # ì¶”ê°€ ì¶”ì²œ!\n",
    "    'efficientnet_b3',\n",
    "    'efficientnet_b4',\n",
    "    # 'densenet121',     # ë³´ë„ˆìŠ¤ë¡œ ì¶”ê°€í•´ë„ ì¢‹ìŒ\n",
    "    # 'vit_base_patch16_224',  # ìµœì‹  íŠ¸ë Œë“œ ì‹¤í—˜ìš©\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: resnet18 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 1/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 1/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 1 | Train Loss: 5.0119 | Val Loss: 3.9343 | Val LogLoss: 3.9389 | Valid Accuracy : 8.6869%\n",
      "âœ… Best model saved (LogLoss: 3.9389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 2/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 2/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 2 | Train Loss: 3.4183 | Val Loss: 2.9583 | Val LogLoss: 2.9613 | Valid Accuracy : 21.2121%\n",
      "âœ… Best model saved (LogLoss: 2.9613)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 3/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 3/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 3 | Train Loss: 2.6567 | Val Loss: 2.2055 | Val LogLoss: 2.2084 | Valid Accuracy : 42.6263%\n",
      "âœ… Best model saved (LogLoss: 2.2084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 4/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 4/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 4 | Train Loss: 2.1885 | Val Loss: 1.7845 | Val LogLoss: 1.7870 | Valid Accuracy : 51.1111%\n",
      "âœ… Best model saved (LogLoss: 1.7870)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 5/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 5/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 5 | Train Loss: 1.7882 | Val Loss: 1.4480 | Val LogLoss: 1.4510 | Valid Accuracy : 56.1616%\n",
      "âœ… Best model saved (LogLoss: 1.4510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 6/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 6/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 6 | Train Loss: 1.4970 | Val Loss: 1.1433 | Val LogLoss: 1.1427 | Valid Accuracy : 73.3333%\n",
      "âœ… Best model saved (LogLoss: 1.1427)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 7/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 7/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 7 | Train Loss: 1.2776 | Val Loss: 0.8383 | Val LogLoss: 0.8360 | Valid Accuracy : 84.2424%\n",
      "âœ… Best model saved (LogLoss: 0.8360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 8/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 8/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 8 | Train Loss: 1.1155 | Val Loss: 0.7055 | Val LogLoss: 0.7035 | Valid Accuracy : 85.4545%\n",
      "âœ… Best model saved (LogLoss: 0.7035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 9/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 9/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 9 | Train Loss: 0.9741 | Val Loss: 0.6016 | Val LogLoss: 0.5985 | Valid Accuracy : 86.6667%\n",
      "âœ… Best model saved (LogLoss: 0.5985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 10/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 10/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 10 | Train Loss: 0.8644 | Val Loss: 0.4645 | Val LogLoss: 0.4616 | Valid Accuracy : 90.3030%\n",
      "âœ… Best model saved (LogLoss: 0.4616)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 11/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:52<00:00,  1.69s/it]\n",
      "[resnet18 Epoch 11/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 11 | Train Loss: 0.7829 | Val Loss: 0.4678 | Val LogLoss: 0.4629 | Valid Accuracy : 89.6970%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 12/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 12/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 12 | Train Loss: 0.6919 | Val Loss: 0.4349 | Val LogLoss: 0.4323 | Valid Accuracy : 91.5152%\n",
      "âœ… Best model saved (LogLoss: 0.4323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 13/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 13/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 13 | Train Loss: 0.6217 | Val Loss: 0.4823 | Val LogLoss: 0.4745 | Valid Accuracy : 89.2929%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 14/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 14/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 14 | Train Loss: 0.6188 | Val Loss: 0.3015 | Val LogLoss: 0.2998 | Valid Accuracy : 93.1313%\n",
      "âœ… Best model saved (LogLoss: 0.2998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 15/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 15/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 15 | Train Loss: 0.5976 | Val Loss: 0.3558 | Val LogLoss: 0.3531 | Valid Accuracy : 91.9192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 16/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 16/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 16 | Train Loss: 0.5046 | Val Loss: 0.3028 | Val LogLoss: 0.3018 | Valid Accuracy : 93.9394%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 17/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 17/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.32it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 17 | Train Loss: 0.4710 | Val Loss: 0.3226 | Val LogLoss: 0.3185 | Valid Accuracy : 91.9192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 18/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 18/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 18 | Train Loss: 0.5045 | Val Loss: 0.2210 | Val LogLoss: 0.2210 | Valid Accuracy : 95.7576%\n",
      "âœ… Best model saved (LogLoss: 0.2210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 19/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 19/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 19 | Train Loss: 0.4601 | Val Loss: 0.2898 | Val LogLoss: 0.2863 | Valid Accuracy : 92.3232%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 20/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 20/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 20 | Train Loss: 0.4396 | Val Loss: 0.1954 | Val LogLoss: 0.1947 | Valid Accuracy : 95.5556%\n",
      "âœ… Best model saved (LogLoss: 0.1947)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 21/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 21/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 21 | Train Loss: 0.4270 | Val Loss: 0.2668 | Val LogLoss: 0.2648 | Valid Accuracy : 93.9394%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 22/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 22/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 22 | Train Loss: 0.4016 | Val Loss: 0.2047 | Val LogLoss: 0.2043 | Valid Accuracy : 95.1515%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 23/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 23/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 23 | Train Loss: 0.3731 | Val Loss: 0.2365 | Val LogLoss: 0.2359 | Valid Accuracy : 94.9495%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 24/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 24/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 24 | Train Loss: 0.3172 | Val Loss: 0.2331 | Val LogLoss: 0.2323 | Valid Accuracy : 95.9596%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 25/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 25/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 25 | Train Loss: 0.3184 | Val Loss: 0.1811 | Val LogLoss: 0.1800 | Valid Accuracy : 96.9697%\n",
      "âœ… Best model saved (LogLoss: 0.1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 26/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 26/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 26 | Train Loss: 0.3221 | Val Loss: 0.1797 | Val LogLoss: 0.1784 | Valid Accuracy : 96.3636%\n",
      "âœ… Best model saved (LogLoss: 0.1784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 27/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 27/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 27 | Train Loss: 0.3228 | Val Loss: 0.1681 | Val LogLoss: 0.1667 | Valid Accuracy : 96.3636%\n",
      "âœ… Best model saved (LogLoss: 0.1667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 28/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 28/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 28 | Train Loss: 0.2779 | Val Loss: 0.1648 | Val LogLoss: 0.1639 | Valid Accuracy : 96.1616%\n",
      "âœ… Best model saved (LogLoss: 0.1639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 29/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:50<00:00,  1.64s/it]\n",
      "[resnet18 Epoch 29/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.29it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 29 | Train Loss: 0.3036 | Val Loss: 0.1662 | Val LogLoss: 0.1654 | Valid Accuracy : 96.5657%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 30/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 30/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 30 | Train Loss: 0.2868 | Val Loss: 0.1785 | Val LogLoss: 0.1769 | Valid Accuracy : 96.3636%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 31/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 31/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 31 | Train Loss: 0.2770 | Val Loss: 0.1769 | Val LogLoss: 0.1756 | Valid Accuracy : 96.5657%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 32/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 32/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 32 | Train Loss: 0.2630 | Val Loss: 0.1669 | Val LogLoss: 0.1662 | Valid Accuracy : 96.9697%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 33/Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 33/Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 33 | Train Loss: 0.2718 | Val Loss: 0.1716 | Val LogLoss: 0.1709 | Valid Accuracy : 96.7677%\n",
      "ğŸ›‘ Early stopping at epoch 33\n",
      "\n",
      "ğŸš€ Training Model: densenet121 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 1/Train]:   0%|          | 0/31 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.88 MiB is free. Process 644826 has 17.11 GiB memory in use. Process 700581 has 6.56 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 113.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# logits\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(features)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:90\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     92\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.88 MiB is free. Process 644826 has 17.11 GiB memory in use. Process 700581 has 6.56 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 113.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for backbone_name in models:\n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name = backbone_name).to(device)\n",
    "\n",
    "    print(f\"\\nğŸš€ Training Model: {backbone_name} \\n\\n\")\n",
    "    # ê¸°ì¤€ê°’ ì´ˆê¸°í™”\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    # ì†ì‹¤ í•¨ìˆ˜\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ì˜µí‹°ë§ˆì´ì €\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "    # ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    # í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ \n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # LogLoss\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "                f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "                f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "        \n",
    "        scheduler.step(val_logloss)\n",
    "\n",
    "        # Best model ì €ì¥\n",
    "        \n",
    "        if val_logloss < best_logloss:\n",
    "            best_logloss = val_logloss\n",
    "            no_improve = 0\n",
    "        # ëª¨ë¸ ì €ì¥ ì‹œ ì „ì²´ ìƒíƒœ í¬í•¨\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'best_logloss': best_logloss,\n",
    "            'no_improve': no_improve\n",
    "                }, f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "            print(f\"âœ… Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"ğŸ›‘ Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    del model  # ëª¨ë¸ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ í•´ì œ  \n",
    "    del outputs, loss  # í•™ìŠµ í›„ ì¦‰ì‹œ ì‚­ì œ\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¶”ê°€í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Model: resnet101 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 36/Train]:  21%|â–ˆâ–ˆ        | 86/415 [02:37<10:03,  1.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     18\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     img_path, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[idx]\n\u001b[0;32m---> 39\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     41\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## ì‘ì„±ì¤‘\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "backbone_name = 'resnet101'\n",
    "\n",
    "checkpoint = torch.load('best_resnet101_epoch35.pth')\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "best_logloss = checkpoint['best_logloss']  # ì´ì „ best_logloss ìœ ì§€\n",
    "no_improve = checkpoint['no_improve']      # ì´ì „ no_improve ìœ ì§€\n",
    "start_epoch = checkpoint['epoch'] + 1      # ì´ì–´ì„œ í•™ìŠµí•  ì—í¬í¬\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 5  # ì²´í¬í¬ì¸íŠ¸ì— ì €ì¥ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì§ì ‘ ì •ì˜\n",
    "\n",
    "# ì´ì–´ì„œ í•™ìŠµ\n",
    "for epoch in range(start_epoch, 60):  # 11~20ì—í¬í¬\n",
    "    print(f\"\\nğŸš€ Training Model: {backbone_name} \\n\\n\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # ì¶”ê°€ í•™ìŠµ ì „ ê²€ì¦ ìˆ˜í–‰ìœ¼ë¡œ best_logloss ì´ˆê¸°í™”\n",
    "    model.eval()\n",
    "    # val_loss, val_logloss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "            f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "    \n",
    "    scheduler.step(val_logloss)\n",
    "\n",
    "    # Best model ì €ì¥\n",
    "    \n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'best_logloss': best_logloss,\n",
    "            'no_improve': no_improve\n",
    "        }, f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "        print(f\"âœ… Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"ğŸ›‘ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "del model  # ëª¨ë¸ í•™ìŠµ í›„ ë©”ëª¨ë¦¬ í•´ì œ\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "# records = ['best_densenet121_epoch7.pth','best_efficientnet_b3_epoch10.pth',\n",
    "        #    'best_efficientnet_b4_epoch10.pth','best_resnet101_epoch8.pth']\n",
    "records = ['best_resnet101_epoch35.pth']\n",
    "for record in records:\n",
    "    # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n",
    "    parts = record.split('_')\n",
    "# ì˜¬ë°”ë¥¸ ì¡°ê±´ë¬¸\n",
    "    if record in ['best_resnet18_epoch17.pth', 'best_resnet101_epoch35.pth']:\n",
    "        backbone_name = f\"{parts[1]}\"  # densenet121 ë“±\n",
    "    else:\n",
    "        backbone_name = f\"{parts[1]}_{parts[2]}\"  # efficientnet_b3 ë“±\n",
    "    \n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name=backbone_name)\n",
    "    model.load_state_dict(torch.load(record, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # ì¶”ë¡ \n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            for prob in probs.cpu():  # prob: (num_classes,)\n",
    "                result = {\n",
    "                    class_names[i]: prob[i].item()\n",
    "                    for i in range(len(class_names))\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    pred = pd.DataFrame(results)\n",
    "\n",
    "    submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "    \n",
    "    class_columns = submission.columns[1:]\n",
    "    pred.columns = normalize_cols(pred.columns)\n",
    "    class_columns = normalize_cols(class_columns)\n",
    "    pred = pred[class_columns]\n",
    "\n",
    "    submission[class_columns] = pred.values\n",
    "    submission.to_csv(f'{record}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015</th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019</th>\n",
       "      <th>1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021</th>\n",
       "      <th>2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024</th>\n",
       "      <th>3008_2á„‰á…¦á„ƒá…¢_2018_2023</th>\n",
       "      <th>3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012</th>\n",
       "      <th>3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022</th>\n",
       "      <th>á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016</th>\n",
       "      <th>á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023</th>\n",
       "      <th>á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022</th>\n",
       "      <th>á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018</th>\n",
       "      <th>á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022</th>\n",
       "      <th>á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022</th>\n",
       "      <th>á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.511935e-07</td>\n",
       "      <td>1.445385e-06</td>\n",
       "      <td>1.592065e-07</td>\n",
       "      <td>4.357784e-06</td>\n",
       "      <td>3.298061e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.070755e-07</td>\n",
       "      <td>7.793965e-07</td>\n",
       "      <td>2.955839e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.812796e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.839943e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.176699e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.151721e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.752513e-05</td>\n",
       "      <td>9.487465e-05</td>\n",
       "      <td>1.280151e-04</td>\n",
       "      <td>3.506709e-05</td>\n",
       "      <td>3.918644e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.326350e-04</td>\n",
       "      <td>7.821716e-05</td>\n",
       "      <td>1.066425e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.235167e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.742213e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.497383e-05</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5.077703e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.293226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629503e-05</td>\n",
       "      <td>1.849107e-05</td>\n",
       "      <td>1.507656e-04</td>\n",
       "      <td>6.678894e-06</td>\n",
       "      <td>6.522421e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.378862e-04</td>\n",
       "      <td>1.058777e-05</td>\n",
       "      <td>5.987513e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142872e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.057245e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.381332e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.378176e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.411537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.519213e-06</td>\n",
       "      <td>1.676211e-07</td>\n",
       "      <td>1.582139e-06</td>\n",
       "      <td>5.283350e-07</td>\n",
       "      <td>2.171661e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.027208e-05</td>\n",
       "      <td>3.179571e-06</td>\n",
       "      <td>2.785918e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961595e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.668167e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.549510e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.212071e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.782074e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.922888e-04</td>\n",
       "      <td>5.125251e-03</td>\n",
       "      <td>4.367732e-05</td>\n",
       "      <td>5.357838e-06</td>\n",
       "      <td>1.428535e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.358307e-06</td>\n",
       "      <td>1.325173e-06</td>\n",
       "      <td>5.119073e-05</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.372026e-06</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.196302e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.170576e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.873700e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.729611e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015  1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019  1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024  \\\n",
       "0           7.511935e-07           1.445385e-06           1.592065e-07   \n",
       "1           5.752513e-05           9.487465e-05           1.280151e-04   \n",
       "2           5.629503e-05           1.849107e-05           1.507656e-04   \n",
       "3           3.519213e-06           1.676211e-07           1.582139e-06   \n",
       "4           1.922888e-04           5.125251e-03           4.367732e-05   \n",
       "\n",
       "   2008_2015_2017  2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024  \\\n",
       "0    4.357784e-06                     3.298061e-07   \n",
       "1    3.506709e-05                     3.918644e-05   \n",
       "2    6.678894e-06                     6.522421e-05   \n",
       "3    5.283350e-07                     2.171661e-06   \n",
       "4    5.357838e-06                     1.428535e-05   \n",
       "\n",
       "   2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021  2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024  \\\n",
       "0                              0.000002                          7.070755e-07   \n",
       "1                              0.000038                          6.326350e-04   \n",
       "2                              0.000003                          2.378862e-04   \n",
       "3                              0.000002                          2.027208e-05   \n",
       "4                              0.000098                          1.358307e-06   \n",
       "\n",
       "   3008_2á„‰á…¦á„ƒá…¢_2018_2023  3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012  3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018  ...  \\\n",
       "0          7.793965e-07           2.955839e-07               0.000001  ...   \n",
       "1          7.821716e-05           1.066425e-04               0.000031  ...   \n",
       "2          1.058777e-05           5.987513e-07               0.000010  ...   \n",
       "3          3.179571e-06           2.785918e-06               0.000004  ...   \n",
       "4          1.325173e-06           5.119073e-05               0.000526  ...   \n",
       "\n",
       "   á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022  á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016  á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023  \\\n",
       "0            5.704890e-07            0.000002            8.812796e-07   \n",
       "1            7.235167e-05            0.000015            1.742213e-05   \n",
       "2            1.142872e-05            0.000008            1.057245e-04   \n",
       "3            3.961595e-07            0.000004            3.668167e-05   \n",
       "4            1.372026e-06            0.000060            1.196302e-06   \n",
       "\n",
       "   á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022  á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018  á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022  \\\n",
       "0                0.000001              2.839943e-06               0.000003   \n",
       "1                0.000015              2.497383e-05               0.000106   \n",
       "2                0.000014              2.381332e-05               0.000005   \n",
       "3                0.000008              8.549510e-07               0.000019   \n",
       "4                0.000009              3.170576e-07               0.000004   \n",
       "\n",
       "   á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025  á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018  á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022  \\\n",
       "0          1.176699e-05                  0.000002                  0.000012   \n",
       "1          5.077703e-05                  0.000010                  0.000041   \n",
       "2          1.378176e-05                  0.000003                  0.000029   \n",
       "3          1.212071e-05                  0.000002                  0.000006   \n",
       "4          4.873700e-07                  0.000006                  0.000002   \n",
       "\n",
       "   á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020  \n",
       "0          1.151721e-06  \n",
       "1          1.293226e-05  \n",
       "2          2.411537e-06  \n",
       "3          5.782074e-07  \n",
       "4          6.729611e-06  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F20_2013_2015</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F20_2016_2019</th>\n",
       "      <th>1ì‹œë¦¬ì¦ˆ_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021</th>\n",
       "      <th>2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024</th>\n",
       "      <th>3008_2ì„¸ëŒ€_2018_2023</th>\n",
       "      <th>3ì‹œë¦¬ì¦ˆ_E90_2005_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>í‹°ë³¼ë¦¬_ì—ì–´_2021_2022</th>\n",
       "      <th>íŒŒë‚˜ë©”ë¼_2010_2016</th>\n",
       "      <th>íŒŒë‚˜ë©”ë¼_971_2017_2023</th>\n",
       "      <th>íŒŒì‚¬íŠ¸_GT_B8_2018_2022</th>\n",
       "      <th>íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018</th>\n",
       "      <th>íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022</th>\n",
       "      <th>íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022</th>\n",
       "      <th>í”„ë¦¬ìš°ìŠ¤_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  1ì‹œë¦¬ì¦ˆ_F20_2013_2015  1ì‹œë¦¬ì¦ˆ_F20_2016_2019  1ì‹œë¦¬ì¦ˆ_F40_2020_2024  \\\n",
       "0  TEST_00000                   1                 0.0                 0.0   \n",
       "1  TEST_00001                   1                 0.0                 0.0   \n",
       "2  TEST_00002                   1                 0.0                 0.0   \n",
       "3  TEST_00003                   1                 0.0                 0.0   \n",
       "4  TEST_00004                   1                 0.0                 0.0   \n",
       "\n",
       "   2008_2015_2017  2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024  2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021  \\\n",
       "0             0.0                      0.0                         0.0   \n",
       "1             0.0                      0.0                         0.0   \n",
       "2             0.0                      0.0                         0.0   \n",
       "3             0.0                      0.0                         0.0   \n",
       "4             0.0                      0.0                         0.0   \n",
       "\n",
       "   2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024  3008_2ì„¸ëŒ€_2018_2023  3ì‹œë¦¬ì¦ˆ_E90_2005_2012  ...  \\\n",
       "0                         0.0                 0.0                 0.0  ...   \n",
       "1                         0.0                 0.0                 0.0  ...   \n",
       "2                         0.0                 0.0                 0.0  ...   \n",
       "3                         0.0                 0.0                 0.0  ...   \n",
       "4                         0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   í‹°ë³¼ë¦¬_ì—ì–´_2021_2022  íŒŒë‚˜ë©”ë¼_2010_2016  íŒŒë‚˜ë©”ë¼_971_2017_2023  íŒŒì‚¬íŠ¸_GT_B8_2018_2022  \\\n",
       "0               0.0             0.0                 0.0                  0.0   \n",
       "1               0.0             0.0                 0.0                  0.0   \n",
       "2               0.0             0.0                 0.0                  0.0   \n",
       "3               0.0             0.0                 0.0                  0.0   \n",
       "4               0.0             0.0                 0.0                  0.0   \n",
       "\n",
       "   íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018  íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022  íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025  í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018  \\\n",
       "0                0.0              0.0             0.0                 0.0   \n",
       "1                0.0              0.0             0.0                 0.0   \n",
       "2                0.0              0.0             0.0                 0.0   \n",
       "3                0.0              0.0             0.0                 0.0   \n",
       "4                0.0              0.0             0.0                 0.0   \n",
       "\n",
       "   í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022  í”„ë¦¬ìš°ìŠ¤_C_2018_2020  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1ì‹œë¦¬ì¦ˆ_F20_2013_2015', '1ì‹œë¦¬ì¦ˆ_F20_2016_2019', '1ì‹œë¦¬ì¦ˆ_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024',\n",
      "       '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021', '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024',\n",
      "       '3008_2ì„¸ëŒ€_2018_2023', '3ì‹œë¦¬ì¦ˆ_E90_2005_2012', '3ì‹œë¦¬ì¦ˆ_F30_2013_2018',\n",
      "       ...\n",
      "       'í‹°ë³¼ë¦¬_ì—ì–´_2021_2022', 'íŒŒë‚˜ë©”ë¼_2010_2016', 'íŒŒë‚˜ë©”ë¼_971_2017_2023',\n",
      "       'íŒŒì‚¬íŠ¸_GT_B8_2018_2022', 'íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018', 'íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022',\n",
      "       'íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022',\n",
      "       'í”„ë¦¬ìš°ìŠ¤_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "class_columns = submission.columns[1:]\n",
    "\n",
    "print(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015', '1á„‰á…µá„…á…µá„Œá…³_F20_2016_2019',\n",
      "       '1á„‰á…µá„…á…µá„Œá…³_F40_2020_2024', '2008_2015_2017',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„€á…³á„…á…¡á†«á„á…®á„‘á…¦_F44_2020_2024',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_F45_2019_2021',\n",
      "       '2á„‰á…µá„…á…µá„Œá…³_á„‹á…¢á†¨á„á…µá„‡á…³_á„á…®á„‹á…¥á„…á…¥_U06_2022_2024', '3008_2á„‰á…¦á„ƒá…¢_2018_2023',\n",
      "       '3á„‰á…µá„…á…µá„Œá…³_E90_2005_2012', '3á„‰á…µá„…á…µá„Œá…³_F30_2013_2018',\n",
      "       ...\n",
      "       'á„á…µá„‡á…©á†¯á„…á…µ_á„‹á…¦á„‹á…¥_2021_2022', 'á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_2010_2016',\n",
      "       'á„‘á…¡á„‚á…¡á„†á…¦á„…á…¡_971_2017_2023', 'á„‘á…¡á„‰á…¡á„á…³_GT_B8_2018_2022',\n",
      "       'á„‘á…¡á„‹á…µá†¯á„…á…¥á†º_3á„‰á…¦á„ƒá…¢_2016_2018', 'á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_2019_2022',\n",
      "       'á„‘á…¢á†¯á„…á…µá„‰á…¦á„‹á…µá„ƒá…³_LX3_2025', 'á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2016_2018',\n",
      "       'á„‘á…³á„…á…µá„‹á…®á„‰á…³_4á„‰á…¦á„ƒá…¢_2019_2022', 'á„‘á…³á„…á…µá„‹á…®á„‰á…³_C_2018_2020'],\n",
      "      dtype='object', length=396)\n",
      "Index(['1ì‹œë¦¬ì¦ˆ_F20_2013_2015', '1ì‹œë¦¬ì¦ˆ_F20_2016_2019', '1ì‹œë¦¬ì¦ˆ_F40_2020_2024',\n",
      "       '2008_2015_2017', '2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024',\n",
      "       '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021', '2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024',\n",
      "       '3008_2ì„¸ëŒ€_2018_2023', '3ì‹œë¦¬ì¦ˆ_E90_2005_2012', '3ì‹œë¦¬ì¦ˆ_F30_2013_2018',\n",
      "       ...\n",
      "       'í‹°ë³¼ë¦¬_ì—ì–´_2021_2022', 'íŒŒë‚˜ë©”ë¼_2010_2016', 'íŒŒë‚˜ë©”ë¼_971_2017_2023',\n",
      "       'íŒŒì‚¬íŠ¸_GT_B8_2018_2022', 'íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018', 'íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022',\n",
      "       'íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018', 'í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022',\n",
      "       'í”„ë¦¬ìš°ìŠ¤_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "print(pred.columns)\n",
    "print(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ëª…ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "if list(pred.columns) == list(class_columns):\n",
    "    print(\"ì»¬ëŸ¼ëª…ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ì»¬ëŸ¼ëª…ì´ ë‹¤ë¦…ë‹ˆë‹¤!\")\n",
    "    print(\"predì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:\", set(pred.columns) - set(class_columns))\n",
    "    print(\"class_columnsì—ë§Œ ìˆëŠ” ì»¬ëŸ¼:\", set(class_columns) - set(pred.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEtric = LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "\n",
    "def multiclass_log_loss(answer_df, submission_df):\n",
    "    class_list = sorted(answer_df['label'].unique())\n",
    "    \n",
    "    if submission_df.shape[0] != answer_df.shape[0]:\n",
    "        raise ValueError(\"submission_df í–‰ ê°œìˆ˜ê°€ answer_dfì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    if not all(answer_df['ID'] == submission_df['ID']):\n",
    "        raise ValueError(\"IDê°€ ì •ë ¬ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    missing_cols = [col for col in class_list if col not in submission_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"í´ë˜ìŠ¤ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}\")\n",
    "    \n",
    "    if submission_df[class_list].isnull().any().any():\n",
    "        raise ValueError(\"NaN í¬í•¨ë¨\")\n",
    "    for col in class_list:\n",
    "        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():\n",
    "            raise ValueError(f\"{col}ì˜ í™•ë¥ ê°’ì´ 0~1 ë²”ìœ„ ì´ˆê³¼\")\n",
    "\n",
    "    # ì •ë‹µ ì¸ë±ìŠ¤ ë³€í™˜\n",
    "    true_labels = answer_df['label'].tolist()\n",
    "    true_idx = [class_list.index(lbl) for lbl in true_labels]\n",
    "\n",
    "    # í™•ë¥  ì •ê·œí™” + clip\n",
    "    probs = submission_df[class_list].values\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° (í´ë˜ìŠ¤ 3ê°œ: A, B, C)\n",
    "answer_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'label': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'A': [0.7, 0.1, 0.2],\n",
    "    'B': [0.2, 0.8, 0.3],\n",
    "    'C': [0.1, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "loss = multiclass_log_loss(answer_df, submission_df)\n",
    "print(f\"Log Loss: {loss:.6f}\") # Log Loss: 0.424322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
