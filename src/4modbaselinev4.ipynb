{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\n",
    "#     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.models as tv_models\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import unicodedata\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 40,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # 테스트셋: 라벨 없이 이미지 경로만 저장\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = '../data/train'\n",
    "test_root = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    # transforms.RandomSolarize(threshold=192.0, p=0.1),\n",
    "    transforms.RandomInvert(p=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "'''\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(CFG['IMG_SIZE'], scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),  # PIL.Image에 적용\n",
    "    transforms.ToTensor(),  # 여기까지는 PIL.Image 변환\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),  # Tensor에 적용\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "'''\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30개 데이터셋만 샘플링해서 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터셋 크기: 33137\n",
      "선택 클래스 수: 30\n",
      "선택 샘플 수: 2474\n",
      "학습 데이터 크기: 1979, 검증 데이터 크기: 495\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 로드\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"원본 데이터셋 크기: {len(full_dataset)}\")\n",
    "\n",
    "# 1. 30개 클래스 무작위 선택\n",
    "all_classes = full_dataset.classes\n",
    "np.random.seed(42)  # 재현성 보장\n",
    "selected_classes = np.random.choice(all_classes, size=30, replace=False)\n",
    "\n",
    "# 2. 선택된 클래스의 인덱스 추출\n",
    "selected_class_indices = [full_dataset.class_to_idx[cls] for cls in selected_classes]\n",
    "\n",
    "# 3. 선택된 클래스에 해당하는 샘플 인덱스 추출\n",
    "selected_sample_indices = [\n",
    "    i for i, (_, label) in enumerate(full_dataset.samples) \n",
    "    if label in selected_class_indices\n",
    "]\n",
    "\n",
    "# 4. 선택된 샘플의 라벨 추출 (stratified split을 위해)\n",
    "selected_labels = [full_dataset.samples[i][1] for i in selected_sample_indices]\n",
    "\n",
    "# 5. Stratified Split 수행 (80:20 비율)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    selected_sample_indices,\n",
    "    test_size=0.2,\n",
    "    stratify=selected_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. 서브셋 생성 (트랜스포메이션 적용)\n",
    "train_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=train_transform), \n",
    "    train_idx\n",
    ")\n",
    "val_dataset = Subset(\n",
    "    CustomImageDataset(train_root, transform=val_transform), \n",
    "    val_idx\n",
    ")\n",
    "\n",
    "print(f\"선택 클래스 수: {len(selected_classes)}\")\n",
    "print(f\"선택 샘플 수: {len(selected_sample_indices)}\")\n",
    "print(f\"학습 데이터 크기: {len(train_dataset)}, 검증 데이터 크기: {len(val_dataset)}\")\n",
    "\n",
    "# 7. DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 - 시간이 너무 오려 걸려서 위에 30개 샘플로 실험할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수: 33137\n",
      "train 이미지 수: 26509, valid 이미지 수: 6628\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 로드\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"총 이미지 수: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform 각각 적용\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseModel Define : resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = tv_models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "    \n",
    "\n",
    "model = BaseModel(num_classes=len(class_names)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base4model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, backbone_name='resnet18', pretrained=True):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone_name = backbone_name.lower()\n",
    "        \n",
    "        if self.backbone_name.startswith('resnet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        elif self.backbone_name.startswith('efficientnet'):\n",
    "            self.backbone = timm.create_model(self.backbone_name, pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        # DenseNet 지원 추가!\n",
    "        elif self.backbone_name.startswith('densenet'):\n",
    "            self.backbone = getattr(tv_models, self.backbone_name)(pretrained=pretrained)\n",
    "            self.feature_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.head = nn.Linear(self.feature_dim, num_classes)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"지원하지 않는 backbone: {backbone_name}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.head(features)\n",
    "        return out\n",
    "    \n",
    "# 여기 모델에서 반복문으로 돌리기.\n",
    "models = [\n",
    "    'resnet18',\n",
    "    'densenet121',\n",
    "    'resnet101',         # 추가 추천!\n",
    "    'efficientnet_b3',\n",
    "    'efficientnet_b4',\n",
    "    # 'densenet121',     # 보너스로 추가해도 좋음\n",
    "    # 'vit_base_patch16_224',  # 최신 트렌드 실험용\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: resnet18 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 1/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 1/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 1 | Train Loss: 5.0119 | Val Loss: 3.9343 | Val LogLoss: 3.9389 | Valid Accuracy : 8.6869%\n",
      "✅ Best model saved (LogLoss: 3.9389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 2/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 2/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 2 | Train Loss: 3.4183 | Val Loss: 2.9583 | Val LogLoss: 2.9613 | Valid Accuracy : 21.2121%\n",
      "✅ Best model saved (LogLoss: 2.9613)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 3/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 3/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 3 | Train Loss: 2.6567 | Val Loss: 2.2055 | Val LogLoss: 2.2084 | Valid Accuracy : 42.6263%\n",
      "✅ Best model saved (LogLoss: 2.2084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 4/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 4/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 4 | Train Loss: 2.1885 | Val Loss: 1.7845 | Val LogLoss: 1.7870 | Valid Accuracy : 51.1111%\n",
      "✅ Best model saved (LogLoss: 1.7870)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 5/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 5/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 5 | Train Loss: 1.7882 | Val Loss: 1.4480 | Val LogLoss: 1.4510 | Valid Accuracy : 56.1616%\n",
      "✅ Best model saved (LogLoss: 1.4510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 6/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 6/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 6 | Train Loss: 1.4970 | Val Loss: 1.1433 | Val LogLoss: 1.1427 | Valid Accuracy : 73.3333%\n",
      "✅ Best model saved (LogLoss: 1.1427)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 7/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 7/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 7 | Train Loss: 1.2776 | Val Loss: 0.8383 | Val LogLoss: 0.8360 | Valid Accuracy : 84.2424%\n",
      "✅ Best model saved (LogLoss: 0.8360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 8/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 8/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 8 | Train Loss: 1.1155 | Val Loss: 0.7055 | Val LogLoss: 0.7035 | Valid Accuracy : 85.4545%\n",
      "✅ Best model saved (LogLoss: 0.7035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 9/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 9/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 9 | Train Loss: 0.9741 | Val Loss: 0.6016 | Val LogLoss: 0.5985 | Valid Accuracy : 86.6667%\n",
      "✅ Best model saved (LogLoss: 0.5985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 10/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 10/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 10 | Train Loss: 0.8644 | Val Loss: 0.4645 | Val LogLoss: 0.4616 | Valid Accuracy : 90.3030%\n",
      "✅ Best model saved (LogLoss: 0.4616)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 11/Train]: 100%|██████████| 31/31 [00:52<00:00,  1.69s/it]\n",
      "[resnet18 Epoch 11/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 11 | Train Loss: 0.7829 | Val Loss: 0.4678 | Val LogLoss: 0.4629 | Valid Accuracy : 89.6970%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 12/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 12/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 12 | Train Loss: 0.6919 | Val Loss: 0.4349 | Val LogLoss: 0.4323 | Valid Accuracy : 91.5152%\n",
      "✅ Best model saved (LogLoss: 0.4323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 13/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 13/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 13 | Train Loss: 0.6217 | Val Loss: 0.4823 | Val LogLoss: 0.4745 | Valid Accuracy : 89.2929%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 14/Train]: 100%|██████████| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 14/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 14 | Train Loss: 0.6188 | Val Loss: 0.3015 | Val LogLoss: 0.2998 | Valid Accuracy : 93.1313%\n",
      "✅ Best model saved (LogLoss: 0.2998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 15/Train]: 100%|██████████| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 15/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 15 | Train Loss: 0.5976 | Val Loss: 0.3558 | Val LogLoss: 0.3531 | Valid Accuracy : 91.9192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 16/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 16/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 16 | Train Loss: 0.5046 | Val Loss: 0.3028 | Val LogLoss: 0.3018 | Valid Accuracy : 93.9394%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 17/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 17/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.32it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 17 | Train Loss: 0.4710 | Val Loss: 0.3226 | Val LogLoss: 0.3185 | Valid Accuracy : 91.9192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 18/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 18/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 18 | Train Loss: 0.5045 | Val Loss: 0.2210 | Val LogLoss: 0.2210 | Valid Accuracy : 95.7576%\n",
      "✅ Best model saved (LogLoss: 0.2210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 19/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 19/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 19 | Train Loss: 0.4601 | Val Loss: 0.2898 | Val LogLoss: 0.2863 | Valid Accuracy : 92.3232%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 20/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 20/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 20 | Train Loss: 0.4396 | Val Loss: 0.1954 | Val LogLoss: 0.1947 | Valid Accuracy : 95.5556%\n",
      "✅ Best model saved (LogLoss: 0.1947)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 21/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 21/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 21 | Train Loss: 0.4270 | Val Loss: 0.2668 | Val LogLoss: 0.2648 | Valid Accuracy : 93.9394%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 22/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 22/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 22 | Train Loss: 0.4016 | Val Loss: 0.2047 | Val LogLoss: 0.2043 | Valid Accuracy : 95.1515%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 23/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 23/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 23 | Train Loss: 0.3731 | Val Loss: 0.2365 | Val LogLoss: 0.2359 | Valid Accuracy : 94.9495%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 24/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 24/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 24 | Train Loss: 0.3172 | Val Loss: 0.2331 | Val LogLoss: 0.2323 | Valid Accuracy : 95.9596%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 25/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.65s/it]\n",
      "[resnet18 Epoch 25/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 25 | Train Loss: 0.3184 | Val Loss: 0.1811 | Val LogLoss: 0.1800 | Valid Accuracy : 96.9697%\n",
      "✅ Best model saved (LogLoss: 0.1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 26/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 26/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 26 | Train Loss: 0.3221 | Val Loss: 0.1797 | Val LogLoss: 0.1784 | Valid Accuracy : 96.3636%\n",
      "✅ Best model saved (LogLoss: 0.1784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 27/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 27/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 27 | Train Loss: 0.3228 | Val Loss: 0.1681 | Val LogLoss: 0.1667 | Valid Accuracy : 96.3636%\n",
      "✅ Best model saved (LogLoss: 0.1667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 28/Train]: 100%|██████████| 31/31 [00:52<00:00,  1.68s/it]\n",
      "[resnet18 Epoch 28/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 28 | Train Loss: 0.2779 | Val Loss: 0.1648 | Val LogLoss: 0.1639 | Valid Accuracy : 96.1616%\n",
      "✅ Best model saved (LogLoss: 0.1639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 29/Train]: 100%|██████████| 31/31 [00:50<00:00,  1.64s/it]\n",
      "[resnet18 Epoch 29/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.29it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 29 | Train Loss: 0.3036 | Val Loss: 0.1662 | Val LogLoss: 0.1654 | Valid Accuracy : 96.5657%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 30/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 30/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 30 | Train Loss: 0.2868 | Val Loss: 0.1785 | Val LogLoss: 0.1769 | Valid Accuracy : 96.3636%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 31/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 31/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 31 | Train Loss: 0.2770 | Val Loss: 0.1769 | Val LogLoss: 0.1756 | Valid Accuracy : 96.5657%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 32/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.66s/it]\n",
      "[resnet18 Epoch 32/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 32 | Train Loss: 0.2630 | Val Loss: 0.1669 | Val LogLoss: 0.1662 | Valid Accuracy : 96.9697%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet18 Epoch 33/Train]: 100%|██████████| 31/31 [00:51<00:00,  1.67s/it]\n",
      "[resnet18 Epoch 33/Val]: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resnet18] Epoch 33 | Train Loss: 0.2718 | Val Loss: 0.1716 | Val LogLoss: 0.1709 | Valid Accuracy : 96.7677%\n",
      "🛑 Early stopping at epoch 33\n",
      "\n",
      "🚀 Training Model: densenet121 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[densenet121 Epoch 1/Train]:   0%|          | 0/31 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.88 MiB is free. Process 644826 has 17.11 GiB memory in use. Process 700581 has 6.56 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 113.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# logits\u001b[39;00m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(features)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:90\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     92\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.88 MiB is free. Process 644826 has 17.11 GiB memory in use. Process 700581 has 6.56 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 113.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for backbone_name in models:\n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name = backbone_name).to(device)\n",
    "\n",
    "    print(f\"\\n🚀 Training Model: {backbone_name} \\n\\n\")\n",
    "    # 기준값 초기화\n",
    "    best_logloss = float('inf')\n",
    "\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    # 손실 함수\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 옵티마이저\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "    # 스케줄러\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    # 학습 및 검증 루프 \n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # LogLoss\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "                f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "                f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "        \n",
    "        scheduler.step(val_logloss)\n",
    "\n",
    "        # Best model 저장\n",
    "        \n",
    "        if val_logloss < best_logloss:\n",
    "            best_logloss = val_logloss\n",
    "            no_improve = 0\n",
    "        # 모델 저장 시 전체 상태 포함\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'best_logloss': best_logloss,\n",
    "            'no_improve': no_improve\n",
    "                }, f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "            print(f\"✅ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"🛑 Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    del model  # 모델 학습 후 메모리 해제  \n",
    "    del outputs, loss  # 학습 후 즉시 삭제\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Model: resnet101 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[resnet101 Epoch 36/Train]:  21%|██        | 86/415 [02:37<10:03,  1.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackbone_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     18\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     img_path, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[idx]\n\u001b[0;32m---> 39\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     41\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 작성중\n",
    "\n",
    "# 모델 불러오기\n",
    "backbone_name = 'resnet101'\n",
    "\n",
    "checkpoint = torch.load('best_resnet101_epoch35.pth')\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "best_logloss = checkpoint['best_logloss']  # 이전 best_logloss 유지\n",
    "no_improve = checkpoint['no_improve']      # 이전 no_improve 유지\n",
    "start_epoch = checkpoint['epoch'] + 1      # 이어서 학습할 에포크\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 5  # 체크포인트에 저장되지 않았다면 직접 정의\n",
    "\n",
    "# 이어서 학습\n",
    "for epoch in range(start_epoch, 60):  # 11~20에포크\n",
    "    print(f\"\\n🚀 Training Model: {backbone_name} \\n\\n\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Train]\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # 추가 학습 전 검증 수행으로 best_logloss 초기화\n",
    "    model.eval()\n",
    "    # val_loss, val_logloss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[{backbone_name} Epoch {epoch+1}/Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"[{backbone_name}] Epoch {epoch+1} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Val LogLoss: {val_logloss:.4f} | \"\n",
    "            f\"Valid Accuracy : {val_accuracy:.4f}%\")    \n",
    "    \n",
    "    scheduler.step(val_logloss)\n",
    "\n",
    "    # Best model 저장\n",
    "    \n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'best_logloss': best_logloss,\n",
    "            'no_improve': no_improve\n",
    "        }, f\"best_{backbone_name}_epoch{epoch+1}.pth\")\n",
    "        print(f\"✅ Best model saved (LogLoss: {val_logloss:.4f})\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"🛑 Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "del model  # 모델 학습 후 메모리 해제\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "# records = ['best_densenet121_epoch7.pth','best_efficientnet_b3_epoch10.pth',\n",
    "        #    'best_efficientnet_b4_epoch10.pth','best_resnet101_epoch8.pth']\n",
    "records = ['best_resnet101_epoch35.pth']\n",
    "for record in records:\n",
    "    # 저장된 모델 로드\n",
    "    parts = record.split('_')\n",
    "# 올바른 조건문\n",
    "    if record in ['best_resnet18_epoch17.pth', 'best_resnet101_epoch35.pth']:\n",
    "        backbone_name = f\"{parts[1]}\"  # densenet121 등\n",
    "    else:\n",
    "        backbone_name = f\"{parts[1]}_{parts[2]}\"  # efficientnet_b3 등\n",
    "    \n",
    "    model = BaseModel(num_classes=len(class_names), backbone_name=backbone_name)\n",
    "    model.load_state_dict(torch.load(record, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    # 추론\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # 각 배치의 확률을 리스트로 변환\n",
    "            for prob in probs.cpu():  # prob: (num_classes,)\n",
    "                result = {\n",
    "                    class_names[i]: prob[i].item()\n",
    "                    for i in range(len(class_names))\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    pred = pd.DataFrame(results)\n",
    "\n",
    "    submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "    # 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
    "    \n",
    "    class_columns = submission.columns[1:]\n",
    "    pred.columns = normalize_cols(pred.columns)\n",
    "    class_columns = normalize_cols(class_columns)\n",
    "    pred = pred[class_columns]\n",
    "\n",
    "    submission[class_columns] = pred.values\n",
    "    submission.to_csv(f'{record}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1시리즈_F20_2013_2015</th>\n",
       "      <th>1시리즈_F20_2016_2019</th>\n",
       "      <th>1시리즈_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2시리즈_그란쿠페_F44_2020_2024</th>\n",
       "      <th>2시리즈_액티브_투어러_F45_2019_2021</th>\n",
       "      <th>2시리즈_액티브_투어러_U06_2022_2024</th>\n",
       "      <th>3008_2세대_2018_2023</th>\n",
       "      <th>3시리즈_E90_2005_2012</th>\n",
       "      <th>3시리즈_F30_2013_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>티볼리_에어_2021_2022</th>\n",
       "      <th>파나메라_2010_2016</th>\n",
       "      <th>파나메라_971_2017_2023</th>\n",
       "      <th>파사트_GT_B8_2018_2022</th>\n",
       "      <th>파일럿_3세대_2016_2018</th>\n",
       "      <th>팰리세이드_2019_2022</th>\n",
       "      <th>팰리세이드_LX3_2025</th>\n",
       "      <th>프리우스_4세대_2016_2018</th>\n",
       "      <th>프리우스_4세대_2019_2022</th>\n",
       "      <th>프리우스_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.511935e-07</td>\n",
       "      <td>1.445385e-06</td>\n",
       "      <td>1.592065e-07</td>\n",
       "      <td>4.357784e-06</td>\n",
       "      <td>3.298061e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.070755e-07</td>\n",
       "      <td>7.793965e-07</td>\n",
       "      <td>2.955839e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>5.704890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.812796e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.839943e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.176699e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.151721e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.752513e-05</td>\n",
       "      <td>9.487465e-05</td>\n",
       "      <td>1.280151e-04</td>\n",
       "      <td>3.506709e-05</td>\n",
       "      <td>3.918644e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>6.326350e-04</td>\n",
       "      <td>7.821716e-05</td>\n",
       "      <td>1.066425e-04</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>7.235167e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.742213e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.497383e-05</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>5.077703e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.293226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629503e-05</td>\n",
       "      <td>1.849107e-05</td>\n",
       "      <td>1.507656e-04</td>\n",
       "      <td>6.678894e-06</td>\n",
       "      <td>6.522421e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.378862e-04</td>\n",
       "      <td>1.058777e-05</td>\n",
       "      <td>5.987513e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142872e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.057245e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.381332e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.378176e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.411537e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.519213e-06</td>\n",
       "      <td>1.676211e-07</td>\n",
       "      <td>1.582139e-06</td>\n",
       "      <td>5.283350e-07</td>\n",
       "      <td>2.171661e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.027208e-05</td>\n",
       "      <td>3.179571e-06</td>\n",
       "      <td>2.785918e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>3.961595e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.668167e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.549510e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.212071e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.782074e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.922888e-04</td>\n",
       "      <td>5.125251e-03</td>\n",
       "      <td>4.367732e-05</td>\n",
       "      <td>5.357838e-06</td>\n",
       "      <td>1.428535e-05</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.358307e-06</td>\n",
       "      <td>1.325173e-06</td>\n",
       "      <td>5.119073e-05</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.372026e-06</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.196302e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.170576e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.873700e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.729611e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1시리즈_F20_2013_2015  1시리즈_F20_2016_2019  1시리즈_F40_2020_2024  \\\n",
       "0           7.511935e-07           1.445385e-06           1.592065e-07   \n",
       "1           5.752513e-05           9.487465e-05           1.280151e-04   \n",
       "2           5.629503e-05           1.849107e-05           1.507656e-04   \n",
       "3           3.519213e-06           1.676211e-07           1.582139e-06   \n",
       "4           1.922888e-04           5.125251e-03           4.367732e-05   \n",
       "\n",
       "   2008_2015_2017  2시리즈_그란쿠페_F44_2020_2024  \\\n",
       "0    4.357784e-06                     3.298061e-07   \n",
       "1    3.506709e-05                     3.918644e-05   \n",
       "2    6.678894e-06                     6.522421e-05   \n",
       "3    5.283350e-07                     2.171661e-06   \n",
       "4    5.357838e-06                     1.428535e-05   \n",
       "\n",
       "   2시리즈_액티브_투어러_F45_2019_2021  2시리즈_액티브_투어러_U06_2022_2024  \\\n",
       "0                              0.000002                          7.070755e-07   \n",
       "1                              0.000038                          6.326350e-04   \n",
       "2                              0.000003                          2.378862e-04   \n",
       "3                              0.000002                          2.027208e-05   \n",
       "4                              0.000098                          1.358307e-06   \n",
       "\n",
       "   3008_2세대_2018_2023  3시리즈_E90_2005_2012  3시리즈_F30_2013_2018  ...  \\\n",
       "0          7.793965e-07           2.955839e-07               0.000001  ...   \n",
       "1          7.821716e-05           1.066425e-04               0.000031  ...   \n",
       "2          1.058777e-05           5.987513e-07               0.000010  ...   \n",
       "3          3.179571e-06           2.785918e-06               0.000004  ...   \n",
       "4          1.325173e-06           5.119073e-05               0.000526  ...   \n",
       "\n",
       "   티볼리_에어_2021_2022  파나메라_2010_2016  파나메라_971_2017_2023  \\\n",
       "0            5.704890e-07            0.000002            8.812796e-07   \n",
       "1            7.235167e-05            0.000015            1.742213e-05   \n",
       "2            1.142872e-05            0.000008            1.057245e-04   \n",
       "3            3.961595e-07            0.000004            3.668167e-05   \n",
       "4            1.372026e-06            0.000060            1.196302e-06   \n",
       "\n",
       "   파사트_GT_B8_2018_2022  파일럿_3세대_2016_2018  팰리세이드_2019_2022  \\\n",
       "0                0.000001              2.839943e-06               0.000003   \n",
       "1                0.000015              2.497383e-05               0.000106   \n",
       "2                0.000014              2.381332e-05               0.000005   \n",
       "3                0.000008              8.549510e-07               0.000019   \n",
       "4                0.000009              3.170576e-07               0.000004   \n",
       "\n",
       "   팰리세이드_LX3_2025  프리우스_4세대_2016_2018  프리우스_4세대_2019_2022  \\\n",
       "0          1.176699e-05                  0.000002                  0.000012   \n",
       "1          5.077703e-05                  0.000010                  0.000041   \n",
       "2          1.378176e-05                  0.000003                  0.000029   \n",
       "3          1.212071e-05                  0.000002                  0.000006   \n",
       "4          4.873700e-07                  0.000006                  0.000002   \n",
       "\n",
       "   프리우스_C_2018_2020  \n",
       "0          1.151721e-06  \n",
       "1          1.293226e-05  \n",
       "2          2.411537e-06  \n",
       "3          5.782074e-07  \n",
       "4          6.729611e-06  \n",
       "\n",
       "[5 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1시리즈_F20_2013_2015</th>\n",
       "      <th>1시리즈_F20_2016_2019</th>\n",
       "      <th>1시리즈_F40_2020_2024</th>\n",
       "      <th>2008_2015_2017</th>\n",
       "      <th>2시리즈_그란쿠페_F44_2020_2024</th>\n",
       "      <th>2시리즈_액티브_투어러_F45_2019_2021</th>\n",
       "      <th>2시리즈_액티브_투어러_U06_2022_2024</th>\n",
       "      <th>3008_2세대_2018_2023</th>\n",
       "      <th>3시리즈_E90_2005_2012</th>\n",
       "      <th>...</th>\n",
       "      <th>티볼리_에어_2021_2022</th>\n",
       "      <th>파나메라_2010_2016</th>\n",
       "      <th>파나메라_971_2017_2023</th>\n",
       "      <th>파사트_GT_B8_2018_2022</th>\n",
       "      <th>파일럿_3세대_2016_2018</th>\n",
       "      <th>팰리세이드_2019_2022</th>\n",
       "      <th>팰리세이드_LX3_2025</th>\n",
       "      <th>프리우스_4세대_2016_2018</th>\n",
       "      <th>프리우스_4세대_2019_2022</th>\n",
       "      <th>프리우스_C_2018_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  1시리즈_F20_2013_2015  1시리즈_F20_2016_2019  1시리즈_F40_2020_2024  \\\n",
       "0  TEST_00000                   1                 0.0                 0.0   \n",
       "1  TEST_00001                   1                 0.0                 0.0   \n",
       "2  TEST_00002                   1                 0.0                 0.0   \n",
       "3  TEST_00003                   1                 0.0                 0.0   \n",
       "4  TEST_00004                   1                 0.0                 0.0   \n",
       "\n",
       "   2008_2015_2017  2시리즈_그란쿠페_F44_2020_2024  2시리즈_액티브_투어러_F45_2019_2021  \\\n",
       "0             0.0                      0.0                         0.0   \n",
       "1             0.0                      0.0                         0.0   \n",
       "2             0.0                      0.0                         0.0   \n",
       "3             0.0                      0.0                         0.0   \n",
       "4             0.0                      0.0                         0.0   \n",
       "\n",
       "   2시리즈_액티브_투어러_U06_2022_2024  3008_2세대_2018_2023  3시리즈_E90_2005_2012  ...  \\\n",
       "0                         0.0                 0.0                 0.0  ...   \n",
       "1                         0.0                 0.0                 0.0  ...   \n",
       "2                         0.0                 0.0                 0.0  ...   \n",
       "3                         0.0                 0.0                 0.0  ...   \n",
       "4                         0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   티볼리_에어_2021_2022  파나메라_2010_2016  파나메라_971_2017_2023  파사트_GT_B8_2018_2022  \\\n",
       "0               0.0             0.0                 0.0                  0.0   \n",
       "1               0.0             0.0                 0.0                  0.0   \n",
       "2               0.0             0.0                 0.0                  0.0   \n",
       "3               0.0             0.0                 0.0                  0.0   \n",
       "4               0.0             0.0                 0.0                  0.0   \n",
       "\n",
       "   파일럿_3세대_2016_2018  팰리세이드_2019_2022  팰리세이드_LX3_2025  프리우스_4세대_2016_2018  \\\n",
       "0                0.0              0.0             0.0                 0.0   \n",
       "1                0.0              0.0             0.0                 0.0   \n",
       "2                0.0              0.0             0.0                 0.0   \n",
       "3                0.0              0.0             0.0                 0.0   \n",
       "4                0.0              0.0             0.0                 0.0   \n",
       "\n",
       "   프리우스_4세대_2019_2022  프리우스_C_2018_2020  \n",
       "0                 0.0               0.0  \n",
       "1                 0.0               0.0  \n",
       "2                 0.0               0.0  \n",
       "3                 0.0               0.0  \n",
       "4                 0.0               0.0  \n",
       "\n",
       "[5 rows x 397 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019', '1시리즈_F40_2020_2024',\n",
      "       '2008_2015_2017', '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021', '2시리즈_액티브_투어러_U06_2022_2024',\n",
      "       '3008_2세대_2018_2023', '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016', '파나메라_971_2017_2023',\n",
      "       '파사트_GT_B8_2018_2022', '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018', '프리우스_4세대_2019_2022',\n",
      "       '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "class_columns = submission.columns[1:]\n",
    "\n",
    "print(class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019',\n",
      "       '1시리즈_F40_2020_2024', '2008_2015_2017',\n",
      "       '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021',\n",
      "       '2시리즈_액티브_투어러_U06_2022_2024', '3008_2세대_2018_2023',\n",
      "       '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016',\n",
      "       '파나메라_971_2017_2023', '파사트_GT_B8_2018_2022',\n",
      "       '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018',\n",
      "       '프리우스_4세대_2019_2022', '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n",
      "Index(['1시리즈_F20_2013_2015', '1시리즈_F20_2016_2019', '1시리즈_F40_2020_2024',\n",
      "       '2008_2015_2017', '2시리즈_그란쿠페_F44_2020_2024',\n",
      "       '2시리즈_액티브_투어러_F45_2019_2021', '2시리즈_액티브_투어러_U06_2022_2024',\n",
      "       '3008_2세대_2018_2023', '3시리즈_E90_2005_2012', '3시리즈_F30_2013_2018',\n",
      "       ...\n",
      "       '티볼리_에어_2021_2022', '파나메라_2010_2016', '파나메라_971_2017_2023',\n",
      "       '파사트_GT_B8_2018_2022', '파일럿_3세대_2016_2018', '팰리세이드_2019_2022',\n",
      "       '팰리세이드_LX3_2025', '프리우스_4세대_2016_2018', '프리우스_4세대_2019_2022',\n",
      "       '프리우스_C_2018_2020'],\n",
      "      dtype='object', length=396)\n"
     ]
    }
   ],
   "source": [
    "print(pred.columns)\n",
    "print(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼명이 완전히 일치합니다!\n"
     ]
    }
   ],
   "source": [
    "if list(pred.columns) == list(class_columns):\n",
    "    print(\"컬럼명이 완전히 일치합니다!\")\n",
    "else:\n",
    "    print(\"컬럼명이 다릅니다!\")\n",
    "    print(\"pred에만 있는 컬럼:\", set(pred.columns) - set(class_columns))\n",
    "    print(\"class_columns에만 있는 컬럼:\", set(class_columns) - set(pred.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_cols(cols):\n",
    "    return [unicodedata.normalize('NFC', col) for col in cols]\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
    "\n",
    "pred.columns = normalize_cols(pred.columns)\n",
    "class_columns = normalize_cols(class_columns)\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEtric = LogLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import pandas as pd\n",
    "\n",
    "def multiclass_log_loss(answer_df, submission_df):\n",
    "    class_list = sorted(answer_df['label'].unique())\n",
    "    \n",
    "    if submission_df.shape[0] != answer_df.shape[0]:\n",
    "        raise ValueError(\"submission_df 행 개수가 answer_df와 일치하지 않습니다.\")\n",
    "\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "    answer_df = answer_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    if not all(answer_df['ID'] == submission_df['ID']):\n",
    "        raise ValueError(\"ID가 정렬되지 않았거나 불일치합니다.\")\n",
    "    \n",
    "    missing_cols = [col for col in class_list if col not in submission_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"클래스 컬럼 누락: {missing_cols}\")\n",
    "    \n",
    "    if submission_df[class_list].isnull().any().any():\n",
    "        raise ValueError(\"NaN 포함됨\")\n",
    "    for col in class_list:\n",
    "        if not ((submission_df[col] >= 0) & (submission_df[col] <= 1)).all():\n",
    "            raise ValueError(f\"{col}의 확률값이 0~1 범위 초과\")\n",
    "\n",
    "    # 정답 인덱스 변환\n",
    "    true_labels = answer_df['label'].tolist()\n",
    "    true_idx = [class_list.index(lbl) for lbl in true_labels]\n",
    "\n",
    "    # 확률 정규화 + clip\n",
    "    probs = submission_df[class_list].values\n",
    "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "    y_pred = np.clip(probs, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    return log_loss(true_idx, y_pred, labels=list(range(len(class_list))))\n",
    "\n",
    "# 예시 데이터 (클래스 3개: A, B, C)\n",
    "answer_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'label': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'A': [0.7, 0.1, 0.2],\n",
    "    'B': [0.2, 0.8, 0.3],\n",
    "    'C': [0.1, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# 함수 실행\n",
    "loss = multiclass_log_loss(answer_df, submission_df)\n",
    "print(f\"Log Loss: {loss:.6f}\") # Log Loss: 0.424322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
